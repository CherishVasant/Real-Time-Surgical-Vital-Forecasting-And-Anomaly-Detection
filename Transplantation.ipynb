{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2daa60dd",
   "metadata": {},
   "source": [
    "# Loading library and data\n",
    "\n",
    "To use the VitalDB open dataset, the pandas library is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc80df0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install numba for performance optimization (if not already installed)\n",
    "try:\n",
    "    import numba\n",
    "    print(f\"âœ… Numba {numba.__version__} is already installed\")\n",
    "except ImportError:\n",
    "    print(\"ðŸ“¦ Installing numba for performance optimization...\")\n",
    "    import subprocess\n",
    "    import sys\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"numba\"])\n",
    "    print(\"âœ… Numba installed successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd56684",
   "metadata": {},
   "source": [
    "At first, we need to load 3 endpoints of the VitalDB open dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9cb3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import jit, prange\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df_cases = pd.read_csv(\"https://api.vitaldb.net/cases\")  # clinical information\n",
    "df_trks = pd.read_csv(\"https://api.vitaldb.net/trks\")  # track list\n",
    "df_labs = pd.read_csv('https://api.vitaldb.net/labs')  # laboratory results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ed6d7b",
   "metadata": {},
   "source": [
    "## Using clinical information data\n",
    "Let's visually check the cases and variables of the VitalDB dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2437913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caseid</th>\n",
       "      <th>subjectid</th>\n",
       "      <th>casestart</th>\n",
       "      <th>caseend</th>\n",
       "      <th>anestart</th>\n",
       "      <th>aneend</th>\n",
       "      <th>opstart</th>\n",
       "      <th>opend</th>\n",
       "      <th>adm</th>\n",
       "      <th>dis</th>\n",
       "      <th>...</th>\n",
       "      <th>intraop_colloid</th>\n",
       "      <th>intraop_ppf</th>\n",
       "      <th>intraop_mdz</th>\n",
       "      <th>intraop_ftn</th>\n",
       "      <th>intraop_rocu</th>\n",
       "      <th>intraop_vecu</th>\n",
       "      <th>intraop_eph</th>\n",
       "      <th>intraop_phe</th>\n",
       "      <th>intraop_epi</th>\n",
       "      <th>intraop_ca</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5955</td>\n",
       "      <td>0</td>\n",
       "      <td>11542</td>\n",
       "      <td>-552</td>\n",
       "      <td>10848.0</td>\n",
       "      <td>1668</td>\n",
       "      <td>10368</td>\n",
       "      <td>-236220</td>\n",
       "      <td>627780</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2487</td>\n",
       "      <td>0</td>\n",
       "      <td>15741</td>\n",
       "      <td>-1039</td>\n",
       "      <td>14921.0</td>\n",
       "      <td>1721</td>\n",
       "      <td>14621</td>\n",
       "      <td>-221160</td>\n",
       "      <td>1506840</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2861</td>\n",
       "      <td>0</td>\n",
       "      <td>4394</td>\n",
       "      <td>-590</td>\n",
       "      <td>4210.0</td>\n",
       "      <td>1090</td>\n",
       "      <td>3010</td>\n",
       "      <td>-218640</td>\n",
       "      <td>40560</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1903</td>\n",
       "      <td>0</td>\n",
       "      <td>20990</td>\n",
       "      <td>-778</td>\n",
       "      <td>20222.0</td>\n",
       "      <td>2522</td>\n",
       "      <td>17822</td>\n",
       "      <td>-201120</td>\n",
       "      <td>576480</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4416</td>\n",
       "      <td>0</td>\n",
       "      <td>21531</td>\n",
       "      <td>-1009</td>\n",
       "      <td>22391.0</td>\n",
       "      <td>2591</td>\n",
       "      <td>20291</td>\n",
       "      <td>-67560</td>\n",
       "      <td>3734040</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>900</td>\n",
       "      <td>0</td>\n",
       "      <td>2100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6383</th>\n",
       "      <td>6384</td>\n",
       "      <td>5583</td>\n",
       "      <td>0</td>\n",
       "      <td>15248</td>\n",
       "      <td>-260</td>\n",
       "      <td>15640.0</td>\n",
       "      <td>2140</td>\n",
       "      <td>14140</td>\n",
       "      <td>-215340</td>\n",
       "      <td>648660</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6384</th>\n",
       "      <td>6385</td>\n",
       "      <td>2278</td>\n",
       "      <td>0</td>\n",
       "      <td>20643</td>\n",
       "      <td>-544</td>\n",
       "      <td>20996.0</td>\n",
       "      <td>2396</td>\n",
       "      <td>19496</td>\n",
       "      <td>-225600</td>\n",
       "      <td>1675200</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6385</th>\n",
       "      <td>6386</td>\n",
       "      <td>4045</td>\n",
       "      <td>0</td>\n",
       "      <td>19451</td>\n",
       "      <td>-667</td>\n",
       "      <td>19133.0</td>\n",
       "      <td>3533</td>\n",
       "      <td>18233</td>\n",
       "      <td>-200460</td>\n",
       "      <td>836340</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6386</th>\n",
       "      <td>6387</td>\n",
       "      <td>5230</td>\n",
       "      <td>0</td>\n",
       "      <td>12025</td>\n",
       "      <td>-550</td>\n",
       "      <td>12830.0</td>\n",
       "      <td>1730</td>\n",
       "      <td>11030</td>\n",
       "      <td>-227760</td>\n",
       "      <td>377040</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6387</th>\n",
       "      <td>6388</td>\n",
       "      <td>1306</td>\n",
       "      <td>0</td>\n",
       "      <td>10249</td>\n",
       "      <td>-79</td>\n",
       "      <td>10121.0</td>\n",
       "      <td>2321</td>\n",
       "      <td>9221</td>\n",
       "      <td>-312060</td>\n",
       "      <td>379140</td>\n",
       "      <td>...</td>\n",
       "      <td>500</td>\n",
       "      <td>120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6388 rows Ã— 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      caseid  subjectid  casestart  caseend  anestart   aneend  opstart  \\\n",
       "0          1       5955          0    11542      -552  10848.0     1668   \n",
       "1          2       2487          0    15741     -1039  14921.0     1721   \n",
       "2          3       2861          0     4394      -590   4210.0     1090   \n",
       "3          4       1903          0    20990      -778  20222.0     2522   \n",
       "4          5       4416          0    21531     -1009  22391.0     2591   \n",
       "...      ...        ...        ...      ...       ...      ...      ...   \n",
       "6383    6384       5583          0    15248      -260  15640.0     2140   \n",
       "6384    6385       2278          0    20643      -544  20996.0     2396   \n",
       "6385    6386       4045          0    19451      -667  19133.0     3533   \n",
       "6386    6387       5230          0    12025      -550  12830.0     1730   \n",
       "6387    6388       1306          0    10249       -79  10121.0     2321   \n",
       "\n",
       "      opend     adm      dis  ...  intraop_colloid  intraop_ppf  intraop_mdz  \\\n",
       "0     10368 -236220   627780  ...                0          120          0.0   \n",
       "1     14621 -221160  1506840  ...                0          150          0.0   \n",
       "2      3010 -218640    40560  ...                0            0          0.0   \n",
       "3     17822 -201120   576480  ...                0           80          0.0   \n",
       "4     20291  -67560  3734040  ...                0            0          0.0   \n",
       "...     ...     ...      ...  ...              ...          ...          ...   \n",
       "6383  14140 -215340   648660  ...                0          150          0.0   \n",
       "6384  19496 -225600  1675200  ...                0          100          0.0   \n",
       "6385  18233 -200460   836340  ...                0           70          0.0   \n",
       "6386  11030 -227760   377040  ...                0          120          0.0   \n",
       "6387   9221 -312060   379140  ...              500          120          0.0   \n",
       "\n",
       "     intraop_ftn  intraop_rocu  intraop_vecu  intraop_eph  intraop_phe  \\\n",
       "0            100            70             0           10            0   \n",
       "1              0           100             0           20            0   \n",
       "2              0            50             0            0            0   \n",
       "3            100           100             0           50            0   \n",
       "4              0           160             0           10          900   \n",
       "...          ...           ...           ...          ...          ...   \n",
       "6383           0            90             0           20            0   \n",
       "6384           0           100             0           25           30   \n",
       "6385           0           130             0           10            0   \n",
       "6386           0            50             0            0            0   \n",
       "6387           0            90             0           20            0   \n",
       "\n",
       "      intraop_epi intraop_ca  \n",
       "0               0          0  \n",
       "1               0          0  \n",
       "2               0          0  \n",
       "3               0          0  \n",
       "4               0       2100  \n",
       "...           ...        ...  \n",
       "6383            0          0  \n",
       "6384            0        300  \n",
       "6385            0          0  \n",
       "6386            0          0  \n",
       "6387            0          0  \n",
       "\n",
       "[6388 rows x 74 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "163db1d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "optype\n",
       "Colorectal          1350\n",
       "Biliary/Pancreas     812\n",
       "Others               799\n",
       "Stomach              676\n",
       "Major resection      584\n",
       "Minor resection      553\n",
       "Breast               434\n",
       "Transplantation      403\n",
       "Vascular             262\n",
       "Hepatic              258\n",
       "Thyroid              257\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cases['optype'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59353b62",
   "metadata": {},
   "source": [
    "## Using track list data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "719b4b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caseid</th>\n",
       "      <th>tname</th>\n",
       "      <th>tid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>BIS/BIS</td>\n",
       "      <td>fd869e25ba82a66cc95b38ed47110bf4f14bb368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>BIS/EEG1_WAV</td>\n",
       "      <td>0aa685df768489a18a5e9f53af0d83bf60890c73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>BIS/EEG2_WAV</td>\n",
       "      <td>ad13b2c39b19193c8ae4a2de4f8315f18d61a57e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>BIS/EMG</td>\n",
       "      <td>2525603efe18d982764dbca457affe7a45e766a9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>BIS/SEF</td>\n",
       "      <td>1c91aec859304840dec75acf4a35da78be0e8ef0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486444</th>\n",
       "      <td>6388</td>\n",
       "      <td>Solar8000/VENT_PIP</td>\n",
       "      <td>2d63adbc7e2653f14348e219816673cde3358cf6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486445</th>\n",
       "      <td>6388</td>\n",
       "      <td>Solar8000/VENT_PPLAT</td>\n",
       "      <td>6f6604255858ddc8f6a01b9f4774b0d43105f6da</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486446</th>\n",
       "      <td>6388</td>\n",
       "      <td>Solar8000/VENT_RR</td>\n",
       "      <td>f34f3fae7fd963355c1c7060e1e876d20fa87536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486447</th>\n",
       "      <td>6388</td>\n",
       "      <td>Solar8000/VENT_SET_TV</td>\n",
       "      <td>4a4a55b8aebf9c76a4a76f62a7c1ec6fcb80e618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486448</th>\n",
       "      <td>6388</td>\n",
       "      <td>Solar8000/VENT_TV</td>\n",
       "      <td>77453bd3c4bf24ce13e577781a51929281f3b7f2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>486449 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        caseid                  tname  \\\n",
       "0            1                BIS/BIS   \n",
       "1            1           BIS/EEG1_WAV   \n",
       "2            1           BIS/EEG2_WAV   \n",
       "3            1                BIS/EMG   \n",
       "4            1                BIS/SEF   \n",
       "...        ...                    ...   \n",
       "486444    6388     Solar8000/VENT_PIP   \n",
       "486445    6388   Solar8000/VENT_PPLAT   \n",
       "486446    6388      Solar8000/VENT_RR   \n",
       "486447    6388  Solar8000/VENT_SET_TV   \n",
       "486448    6388      Solar8000/VENT_TV   \n",
       "\n",
       "                                             tid  \n",
       "0       fd869e25ba82a66cc95b38ed47110bf4f14bb368  \n",
       "1       0aa685df768489a18a5e9f53af0d83bf60890c73  \n",
       "2       ad13b2c39b19193c8ae4a2de4f8315f18d61a57e  \n",
       "3       2525603efe18d982764dbca457affe7a45e766a9  \n",
       "4       1c91aec859304840dec75acf4a35da78be0e8ef0  \n",
       "...                                          ...  \n",
       "486444  2d63adbc7e2653f14348e219816673cde3358cf6  \n",
       "486445  6f6604255858ddc8f6a01b9f4774b0d43105f6da  \n",
       "486446  f34f3fae7fd963355c1c7060e1e876d20fa87536  \n",
       "486447  4a4a55b8aebf9c76a4a76f62a7c1ec6fcb80e618  \n",
       "486448  77453bd3c4bf24ce13e577781a51929281f3b7f2  \n",
       "\n",
       "[486449 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b46570f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196 track types\n",
      "BIS/BIS\t91.84408265497808\n",
      "BIS/EEG1_WAV\t91.9067000626174\n",
      "BIS/EEG2_WAV\t91.9067000626174\n",
      "BIS/EMG\t87.30432060112712\n",
      "BIS/SEF\t87.17908578584847\n",
      "BIS/SQI\t91.84408265497808\n",
      "BIS/SR\t87.17908578584847\n",
      "BIS/TOTPOW\t86.8973074514715\n",
      "CardioQ/ABP\t0.4539762053850971\n",
      "CardioQ/CI\t0.4383218534752661\n",
      "CardioQ/CO\t0.4539762053850971\n",
      "CardioQ/FLOW\t0.4539762053850971\n",
      "CardioQ/FTc\t0.4539762053850971\n",
      "CardioQ/FTp\t0.4383218534752661\n",
      "CardioQ/HR\t0.4539762053850971\n",
      "CardioQ/MA\t0.4383218534752661\n",
      "CardioQ/MD\t0.4539762053850971\n",
      "CardioQ/PV\t0.4383218534752661\n",
      "CardioQ/SD\t0.4539762053850971\n",
      "CardioQ/SV\t0.4539762053850971\n",
      "CardioQ/SVI\t0.4383218534752661\n",
      "EV1000/ART_MBP\t9.267376330619912\n",
      "EV1000/CI\t9.658735128365684\n",
      "EV1000/CO\t9.658735128365684\n",
      "EV1000/CVP\t3.678772698810269\n",
      "EV1000/SV\t9.658735128365684\n",
      "EV1000/SVI\t9.658735128365684\n",
      "EV1000/SVR\t3.991859737006888\n",
      "EV1000/SVRI\t3.991859737006888\n",
      "EV1000/SVV\t9.658735128365684\n",
      "FMS/FLOW_RATE\t0.234815278647464\n",
      "FMS/INPUT_AMB_TEMP\t0.234815278647464\n",
      "FMS/INPUT_TEMP\t0.234815278647464\n",
      "FMS/OUTPUT_AMB_TEMP\t0.234815278647464\n",
      "FMS/OUTPUT_TEMP\t0.234815278647464\n",
      "FMS/PRESSURE\t0.234815278647464\n",
      "FMS/TOTAL_VOL\t0.234815278647464\n",
      "Invos/SCO2_L\t0.5165936130244209\n",
      "Invos/SCO2_R\t0.5165936130244209\n",
      "Orchestra/AMD_RATE\t0.015654351909830933\n",
      "Orchestra/AMD_VOL\t0.015654351909830933\n",
      "Orchestra/DEX2_RATE\t0.09392611145898559\n",
      "Orchestra/DEX2_VOL\t0.09392611145898559\n",
      "Orchestra/DEX4_RATE\t0.06261740763932373\n",
      "Orchestra/DEX4_VOL\t0.06261740763932373\n",
      "Orchestra/DOBU_RATE\t0.046963055729492796\n",
      "Orchestra/DOBU_VOL\t0.046963055729492796\n",
      "Orchestra/DOPA_RATE\t0.5165936130244209\n",
      "Orchestra/DOPA_VOL\t0.5165936130244209\n",
      "Orchestra/DTZ_RATE\t0.031308703819661866\n",
      "Orchestra/DTZ_VOL\t0.031308703819661866\n",
      "Orchestra/EPI_RATE\t0.14088916718847838\n",
      "Orchestra/EPI_VOL\t0.14088916718847838\n",
      "Orchestra/FUT_RATE\t1.4715090795241077\n",
      "Orchestra/FUT_VOL\t1.4715090795241077\n",
      "Orchestra/MRN_RATE\t0.07827175954915466\n",
      "Orchestra/MRN_VOL\t0.07827175954915466\n",
      "Orchestra/NEPI_RATE\t1.3775829680651221\n",
      "Orchestra/NEPI_VOL\t1.3775829680651221\n",
      "Orchestra/NPS_RATE\t0.015654351909830933\n",
      "Orchestra/NPS_VOL\t0.015654351909830933\n",
      "Orchestra/NTG_RATE\t0.5009392611145899\n",
      "Orchestra/NTG_VOL\t0.5009392611145899\n",
      "Orchestra/OXY_RATE\t0.046963055729492796\n",
      "Orchestra/OXY_VOL\t0.046963055729492796\n",
      "Orchestra/PGE1_RATE\t1.408891671884784\n",
      "Orchestra/PGE1_VOL\t1.408891671884784\n",
      "Orchestra/PHEN_RATE\t1.9881026925485286\n",
      "Orchestra/PHEN_VOL\t1.9881026925485286\n",
      "Orchestra/PPF20_CE\t54.962429555416406\n",
      "Orchestra/PPF20_CP\t54.962429555416406\n",
      "Orchestra/PPF20_CT\t54.962429555416406\n",
      "Orchestra/PPF20_RATE\t54.97808390732624\n",
      "Orchestra/PPF20_VOL\t54.97808390732624\n",
      "Orchestra/RFTN20_CE\t74.68691296180339\n",
      "Orchestra/RFTN20_CP\t74.68691296180339\n",
      "Orchestra/RFTN20_CT\t74.68691296180339\n",
      "Orchestra/RFTN20_RATE\t74.71822166562305\n",
      "Orchestra/RFTN20_VOL\t74.73387601753288\n",
      "Orchestra/RFTN50_CE\t1.0801502817783344\n",
      "Orchestra/RFTN50_CP\t1.0801502817783344\n",
      "Orchestra/RFTN50_CT\t1.0801502817783344\n",
      "Orchestra/RFTN50_RATE\t1.0801502817783344\n",
      "Orchestra/RFTN50_VOL\t1.0801502817783344\n",
      "Orchestra/ROC_RATE\t4.398872886662493\n",
      "Orchestra/ROC_VOL\t4.398872886662493\n",
      "Orchestra/VASO_RATE\t0.015654351909830933\n",
      "Orchestra/VASO_VOL\t0.015654351909830933\n",
      "Orchestra/VEC_RATE\t0.015654351909830933\n",
      "Orchestra/VEC_VOL\t0.015654351909830933\n",
      "Primus/AWP\t99.56167814652474\n",
      "Primus/CO2\t99.5929868503444\n",
      "Primus/COMPLIANCE\t94.19223544145272\n",
      "Primus/ETCO2\t99.23293675641828\n",
      "Primus/EXP_DES\t32.02880400751409\n",
      "Primus/EXP_SEVO\t57.717595491546646\n",
      "Primus/FEN2O\t99.23293675641828\n",
      "Primus/FEO2\t99.17031934877896\n",
      "Primus/FIN2O\t99.23293675641828\n",
      "Primus/FIO2\t99.17031934877896\n",
      "Primus/FLOW_AIR\t88.35316217908579\n",
      "Primus/FLOW_N2O\t88.35316217908579\n",
      "Primus/FLOW_O2\t88.33750782717595\n",
      "Primus/INCO2\t99.23293675641828\n",
      "Primus/INSP_DES\t32.02880400751409\n",
      "Primus/INSP_SEVO\t57.717595491546646\n",
      "Primus/MAC\t99.21728240450845\n",
      "Primus/MAWP_MBAR\t99.21728240450845\n",
      "Primus/MV\t94.27050720100188\n",
      "Primus/PAMB_MBAR\t99.57733249843457\n",
      "Primus/PEEP_MBAR\t93.91045710707576\n",
      "Primus/PIP_MBAR\t94.03569192235442\n",
      "Primus/PPLAT_MBAR\t93.91045710707576\n",
      "Primus/RR_CO2\t99.06073888541015\n",
      "Primus/SET_AGE\t99.57733249843457\n",
      "Primus/SET_FIO2\t94.66186599874766\n",
      "Primus/SET_FLOW_TRIG\t2.410770194113964\n",
      "Primus/SET_FRESH_FLOW\t94.5835942391985\n",
      "Primus/SET_INSP_PAUSE\t93.36255479023168\n",
      "Primus/SET_INSP_PRES\t5.964308077645585\n",
      "Primus/SET_INSP_TM\t93.61302442078897\n",
      "Primus/SET_INTER_PEEP\t93.61302442078897\n",
      "Primus/SET_PIP\t93.36255479023168\n",
      "Primus/SET_RR_IPPV\t93.61302442078897\n",
      "Primus/SET_TV_L\t93.36255479023168\n",
      "Primus/TV\t94.20788979336255\n",
      "Primus/VENT_LEAK\t99.31120851596744\n",
      "SNUADC/ART\t57.06011271133376\n",
      "SNUADC/CVP\t24.82780212899186\n",
      "SNUADC/ECG_II\t99.48340638697559\n",
      "SNUADC/ECG_V5\t53.06825297432687\n",
      "SNUADC/FEM\t1.9881026925485286\n",
      "SNUADC/PLETH\t96.38384470882906\n",
      "Solar8000/ART_DBP\t58.31246086412023\n",
      "Solar8000/ART_MBP\t58.296806512210395\n",
      "Solar8000/ART_SBP\t58.31246086412023\n",
      "Solar8000/BT\t92.9085785848466\n",
      "Solar8000/CVP\t25.17219787100814\n",
      "Solar8000/ETCO2\t97.7144646211647\n",
      "Solar8000/FEM_DBP\t2.2229179711959923\n",
      "Solar8000/FEM_MBP\t2.2229179711959923\n",
      "Solar8000/FEM_SBP\t2.2229179711959923\n",
      "Solar8000/FEO2\t97.66750156543519\n",
      "Solar8000/FIO2\t97.66750156543519\n",
      "Solar8000/GAS2_EXPIRED\t48.4815278647464\n",
      "Solar8000/GAS2_INSPIRED\t48.4815278647464\n",
      "Solar8000/HR\t99.98434564809017\n",
      "Solar8000/INCO2\t97.7144646211647\n",
      "Solar8000/NIBP_DBP\t90.0281778334377\n",
      "Solar8000/NIBP_MBP\t90.21603005635566\n",
      "Solar8000/NIBP_SBP\t90.0281778334377\n",
      "Solar8000/PA_DBP\t1.2680025046963057\n",
      "Solar8000/PA_MBP\t1.2680025046963057\n",
      "Solar8000/PA_SBP\t1.2680025046963057\n",
      "Solar8000/PLETH_HR\t99.96869129618034\n",
      "Solar8000/PLETH_SPO2\t99.96869129618034\n",
      "Solar8000/RR\t20.256731371321226\n",
      "Solar8000/RR_CO2\t96.69693174702567\n",
      "Solar8000/ST_AVF\t47.025673137132124\n",
      "Solar8000/ST_AVL\t47.025673137132124\n",
      "Solar8000/ST_AVR\t47.025673137132124\n",
      "Solar8000/ST_I\t47.338760175328744\n",
      "Solar8000/ST_II\t93.58171571696931\n",
      "Solar8000/ST_III\t47.385723231058236\n",
      "Solar8000/ST_V5\t0.015654351909830933\n",
      "Solar8000/VENT_COMPL\t1.7845961177207263\n",
      "Solar8000/VENT_INSP_TM\t92.97119599248592\n",
      "Solar8000/VENT_MAWP\t98.60676268002506\n",
      "Solar8000/VENT_MEAS_PEEP\t1.5341264871634315\n",
      "Solar8000/VENT_MV\t93.7226048841578\n",
      "Solar8000/VENT_PIP\t93.4721352536005\n",
      "Solar8000/VENT_PPLAT\t93.29993738259236\n",
      "Solar8000/VENT_RR\t93.7226048841578\n",
      "Solar8000/VENT_SET_FIO2\t34.62742642454602\n",
      "Solar8000/VENT_SET_PCP\t42.97119599248591\n",
      "Solar8000/VENT_SET_TV\t66.57795867251096\n",
      "Solar8000/VENT_TV\t93.61302442078897\n",
      "Vigilance/BT_PA\t1.0018785222291797\n",
      "Vigilance/CI\t1.0175328741390106\n",
      "Vigilance/CO\t1.0175328741390106\n",
      "Vigilance/EDV\t0.7670632435817157\n",
      "Vigilance/EDVI\t0.7670632435817157\n",
      "Vigilance/ESV\t0.7670632435817157\n",
      "Vigilance/ESVI\t0.7670632435817157\n",
      "Vigilance/HR_AVG\t0.8296806512210394\n",
      "Vigilance/RVEF\t0.7514088916718847\n",
      "Vigilance/SNR\t0.9236067626800251\n",
      "Vigilance/SQI\t0.9862241703193488\n",
      "Vigilance/SV\t0.8609893550407014\n",
      "Vigilance/SVI\t0.8609893550407014\n",
      "Vigilance/SVO2\t0.9862241703193488\n",
      "Vigileo/CI\t5.056355666875391\n",
      "Vigileo/CO\t5.056355666875391\n",
      "Vigileo/SV\t5.056355666875391\n",
      "Vigileo/SVI\t5.056355666875391\n",
      "Vigileo/SVV\t5.056355666875391\n"
     ]
    }
   ],
   "source": [
    "print('{} track types'.format(len(df_trks['tname'].unique())))\n",
    "for tname in sorted(df_trks['tname'].unique()):\n",
    "    print('{}\\t{}'.format(tname, (df_trks['tname'] == tname).sum() / len(df_cases) * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb2f8c5",
   "metadata": {},
   "source": [
    "## Using laboratory results data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8ba2a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 lab types\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caseid</th>\n",
       "      <th>dt</th>\n",
       "      <th>name</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>594470</td>\n",
       "      <td>alb</td>\n",
       "      <td>2.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>399575</td>\n",
       "      <td>alb</td>\n",
       "      <td>3.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>12614</td>\n",
       "      <td>alb</td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>137855</td>\n",
       "      <td>alb</td>\n",
       "      <td>3.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>399575</td>\n",
       "      <td>alt</td>\n",
       "      <td>12.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928443</th>\n",
       "      <td>6388</td>\n",
       "      <td>3503</td>\n",
       "      <td>sao2</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928444</th>\n",
       "      <td>6388</td>\n",
       "      <td>408770</td>\n",
       "      <td>wbc</td>\n",
       "      <td>3.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928445</th>\n",
       "      <td>6388</td>\n",
       "      <td>-32848</td>\n",
       "      <td>wbc</td>\n",
       "      <td>6.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928446</th>\n",
       "      <td>6388</td>\n",
       "      <td>-249820</td>\n",
       "      <td>wbc</td>\n",
       "      <td>7.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928447</th>\n",
       "      <td>6388</td>\n",
       "      <td>62645</td>\n",
       "      <td>wbc</td>\n",
       "      <td>11.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>928448 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        caseid      dt  name  result\n",
       "0            1  594470   alb    2.90\n",
       "1            1  399575   alb    3.20\n",
       "2            1   12614   alb    3.40\n",
       "3            1  137855   alb    3.60\n",
       "4            1  399575   alt   12.00\n",
       "...        ...     ...   ...     ...\n",
       "928443    6388    3503  sao2  100.00\n",
       "928444    6388  408770   wbc    3.28\n",
       "928445    6388  -32848   wbc    6.27\n",
       "928446    6388 -249820   wbc    7.66\n",
       "928447    6388   62645   wbc   11.34\n",
       "\n",
       "[928448 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('{} lab types'.format(len(df_labs['name'].unique())))\n",
    "df_labs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f54a2b",
   "metadata": {},
   "source": [
    "## Find a case that satisfies a specific condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71088a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caseid</th>\n",
       "      <th>subjectid</th>\n",
       "      <th>casestart</th>\n",
       "      <th>caseend</th>\n",
       "      <th>anestart</th>\n",
       "      <th>aneend</th>\n",
       "      <th>opstart</th>\n",
       "      <th>opend</th>\n",
       "      <th>adm</th>\n",
       "      <th>dis</th>\n",
       "      <th>...</th>\n",
       "      <th>intraop_colloid</th>\n",
       "      <th>intraop_ppf</th>\n",
       "      <th>intraop_mdz</th>\n",
       "      <th>intraop_ftn</th>\n",
       "      <th>intraop_rocu</th>\n",
       "      <th>intraop_vecu</th>\n",
       "      <th>intraop_eph</th>\n",
       "      <th>intraop_phe</th>\n",
       "      <th>intraop_epi</th>\n",
       "      <th>intraop_ca</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "      <td>31203</td>\n",
       "      <td>-220</td>\n",
       "      <td>31460.0</td>\n",
       "      <td>5360</td>\n",
       "      <td>30860</td>\n",
       "      <td>-208500</td>\n",
       "      <td>1519500</td>\n",
       "      <td>...</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>3720</td>\n",
       "      <td>0</td>\n",
       "      <td>21394</td>\n",
       "      <td>-1176</td>\n",
       "      <td>21324.0</td>\n",
       "      <td>3324</td>\n",
       "      <td>20424</td>\n",
       "      <td>-114540</td>\n",
       "      <td>576660</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>52</td>\n",
       "      <td>1724</td>\n",
       "      <td>0</td>\n",
       "      <td>15590</td>\n",
       "      <td>-1453</td>\n",
       "      <td>15647.0</td>\n",
       "      <td>3647</td>\n",
       "      <td>14747</td>\n",
       "      <td>-220140</td>\n",
       "      <td>1075860</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>54</td>\n",
       "      <td>1517</td>\n",
       "      <td>0</td>\n",
       "      <td>15346</td>\n",
       "      <td>-939</td>\n",
       "      <td>15321.0</td>\n",
       "      <td>2421</td>\n",
       "      <td>14421</td>\n",
       "      <td>-132240</td>\n",
       "      <td>299760</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>55</td>\n",
       "      <td>5077</td>\n",
       "      <td>0</td>\n",
       "      <td>21734</td>\n",
       "      <td>-722</td>\n",
       "      <td>22498.0</td>\n",
       "      <td>3598</td>\n",
       "      <td>21151</td>\n",
       "      <td>-210900</td>\n",
       "      <td>1603500</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6336</th>\n",
       "      <td>6337</td>\n",
       "      <td>5565</td>\n",
       "      <td>0</td>\n",
       "      <td>24223</td>\n",
       "      <td>-449</td>\n",
       "      <td>25651.0</td>\n",
       "      <td>4051</td>\n",
       "      <td>23551</td>\n",
       "      <td>-1286520</td>\n",
       "      <td>1391880</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6343</th>\n",
       "      <td>6344</td>\n",
       "      <td>2628</td>\n",
       "      <td>0</td>\n",
       "      <td>12168</td>\n",
       "      <td>-863</td>\n",
       "      <td>11737.0</td>\n",
       "      <td>2737</td>\n",
       "      <td>10837</td>\n",
       "      <td>-114840</td>\n",
       "      <td>317160</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6345</th>\n",
       "      <td>6346</td>\n",
       "      <td>5525</td>\n",
       "      <td>0</td>\n",
       "      <td>17606</td>\n",
       "      <td>-380</td>\n",
       "      <td>17560.0</td>\n",
       "      <td>2560</td>\n",
       "      <td>16660</td>\n",
       "      <td>-225420</td>\n",
       "      <td>984180</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6362</th>\n",
       "      <td>6363</td>\n",
       "      <td>5396</td>\n",
       "      <td>0</td>\n",
       "      <td>26282</td>\n",
       "      <td>-552</td>\n",
       "      <td>25788.0</td>\n",
       "      <td>2988</td>\n",
       "      <td>23988</td>\n",
       "      <td>-559200</td>\n",
       "      <td>1341600</td>\n",
       "      <td>...</td>\n",
       "      <td>800</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6382</th>\n",
       "      <td>6383</td>\n",
       "      <td>4255</td>\n",
       "      <td>0</td>\n",
       "      <td>23242</td>\n",
       "      <td>-1883</td>\n",
       "      <td>23137.0</td>\n",
       "      <td>3037</td>\n",
       "      <td>22641</td>\n",
       "      <td>-224040</td>\n",
       "      <td>812760</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>403 rows Ã— 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      caseid  subjectid  casestart  caseend  anestart   aneend  opstart  \\\n",
       "11        12        491          0    31203      -220  31460.0     5360   \n",
       "28        29       3720          0    21394     -1176  21324.0     3324   \n",
       "51        52       1724          0    15590     -1453  15647.0     3647   \n",
       "53        54       1517          0    15346      -939  15321.0     2421   \n",
       "54        55       5077          0    21734      -722  22498.0     3598   \n",
       "...      ...        ...        ...      ...       ...      ...      ...   \n",
       "6336    6337       5565          0    24223      -449  25651.0     4051   \n",
       "6343    6344       2628          0    12168      -863  11737.0     2737   \n",
       "6345    6346       5525          0    17606      -380  17560.0     2560   \n",
       "6362    6363       5396          0    26282      -552  25788.0     2988   \n",
       "6382    6383       4255          0    23242     -1883  23137.0     3037   \n",
       "\n",
       "      opend      adm      dis  ...  intraop_colloid  intraop_ppf  intraop_mdz  \\\n",
       "11    30860  -208500  1519500  ...              200          100          0.0   \n",
       "28    20424  -114540   576660  ...                0            0          0.0   \n",
       "51    14747  -220140  1075860  ...               35            0          0.0   \n",
       "53    14421  -132240   299760  ...               35            0          0.0   \n",
       "54    21151  -210900  1603500  ...              100            0          0.0   \n",
       "...     ...      ...      ...  ...              ...          ...          ...   \n",
       "6336  23551 -1286520  1391880  ...               20            0          0.0   \n",
       "6343  10837  -114840   317160  ...                0            0          0.0   \n",
       "6345  16660  -225420   984180  ...               35            0          0.0   \n",
       "6362  23988  -559200  1341600  ...              800            0          0.0   \n",
       "6382  22641  -224040   812760  ...               35            0          0.0   \n",
       "\n",
       "     intraop_ftn  intraop_rocu  intraop_vecu  intraop_eph  intraop_phe  \\\n",
       "11           100            70             0           20            0   \n",
       "28             0           130             0            0            0   \n",
       "51             0           120             0            0            0   \n",
       "53             0            90             0           10            0   \n",
       "54             0            50             0           20            0   \n",
       "...          ...           ...           ...          ...          ...   \n",
       "6336           0             3             0            0            0   \n",
       "6343           0            70             0            0            0   \n",
       "6345           0            80             0            0            0   \n",
       "6362           0            50             0            0            0   \n",
       "6382           0            80             0           10            0   \n",
       "\n",
       "      intraop_epi intraop_ca  \n",
       "11              0       3300  \n",
       "28              0          0  \n",
       "51              0          0  \n",
       "53              0          0  \n",
       "54              0       1200  \n",
       "...           ...        ...  \n",
       "6336            0          0  \n",
       "6343            0          0  \n",
       "6345            0        300  \n",
       "6362            0          0  \n",
       "6382            0        300  \n",
       "\n",
       "[403 rows x 74 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t = df_cases[df_cases['optype'] == \"Transplantation\"]\n",
    "df_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9dd7a689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11        12\n",
       "28        29\n",
       "51        52\n",
       "53        54\n",
       "54        55\n",
       "        ... \n",
       "6336    6337\n",
       "6343    6344\n",
       "6345    6346\n",
       "6362    6363\n",
       "6382    6383\n",
       "Name: caseid, Length: 403, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caseids = df_t['caseid']\n",
    "caseids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4755a582",
   "metadata": {},
   "source": [
    "# Transplantation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ae20314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caseid</th>\n",
       "      <th>subjectid</th>\n",
       "      <th>casestart</th>\n",
       "      <th>caseend</th>\n",
       "      <th>anestart</th>\n",
       "      <th>aneend</th>\n",
       "      <th>opstart</th>\n",
       "      <th>opend</th>\n",
       "      <th>adm</th>\n",
       "      <th>dis</th>\n",
       "      <th>...</th>\n",
       "      <th>intraop_colloid</th>\n",
       "      <th>intraop_ppf</th>\n",
       "      <th>intraop_mdz</th>\n",
       "      <th>intraop_ftn</th>\n",
       "      <th>intraop_rocu</th>\n",
       "      <th>intraop_vecu</th>\n",
       "      <th>intraop_eph</th>\n",
       "      <th>intraop_phe</th>\n",
       "      <th>intraop_epi</th>\n",
       "      <th>intraop_ca</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "      <td>31203</td>\n",
       "      <td>-220</td>\n",
       "      <td>31460.0</td>\n",
       "      <td>5360</td>\n",
       "      <td>30860</td>\n",
       "      <td>-208500</td>\n",
       "      <td>1519500</td>\n",
       "      <td>...</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>3720</td>\n",
       "      <td>0</td>\n",
       "      <td>21394</td>\n",
       "      <td>-1176</td>\n",
       "      <td>21324.0</td>\n",
       "      <td>3324</td>\n",
       "      <td>20424</td>\n",
       "      <td>-114540</td>\n",
       "      <td>576660</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>52</td>\n",
       "      <td>1724</td>\n",
       "      <td>0</td>\n",
       "      <td>15590</td>\n",
       "      <td>-1453</td>\n",
       "      <td>15647.0</td>\n",
       "      <td>3647</td>\n",
       "      <td>14747</td>\n",
       "      <td>-220140</td>\n",
       "      <td>1075860</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>54</td>\n",
       "      <td>1517</td>\n",
       "      <td>0</td>\n",
       "      <td>15346</td>\n",
       "      <td>-939</td>\n",
       "      <td>15321.0</td>\n",
       "      <td>2421</td>\n",
       "      <td>14421</td>\n",
       "      <td>-132240</td>\n",
       "      <td>299760</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>55</td>\n",
       "      <td>5077</td>\n",
       "      <td>0</td>\n",
       "      <td>21734</td>\n",
       "      <td>-722</td>\n",
       "      <td>22498.0</td>\n",
       "      <td>3598</td>\n",
       "      <td>21151</td>\n",
       "      <td>-210900</td>\n",
       "      <td>1603500</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6336</th>\n",
       "      <td>6337</td>\n",
       "      <td>5565</td>\n",
       "      <td>0</td>\n",
       "      <td>24223</td>\n",
       "      <td>-449</td>\n",
       "      <td>25651.0</td>\n",
       "      <td>4051</td>\n",
       "      <td>23551</td>\n",
       "      <td>-1286520</td>\n",
       "      <td>1391880</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6343</th>\n",
       "      <td>6344</td>\n",
       "      <td>2628</td>\n",
       "      <td>0</td>\n",
       "      <td>12168</td>\n",
       "      <td>-863</td>\n",
       "      <td>11737.0</td>\n",
       "      <td>2737</td>\n",
       "      <td>10837</td>\n",
       "      <td>-114840</td>\n",
       "      <td>317160</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6345</th>\n",
       "      <td>6346</td>\n",
       "      <td>5525</td>\n",
       "      <td>0</td>\n",
       "      <td>17606</td>\n",
       "      <td>-380</td>\n",
       "      <td>17560.0</td>\n",
       "      <td>2560</td>\n",
       "      <td>16660</td>\n",
       "      <td>-225420</td>\n",
       "      <td>984180</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6362</th>\n",
       "      <td>6363</td>\n",
       "      <td>5396</td>\n",
       "      <td>0</td>\n",
       "      <td>26282</td>\n",
       "      <td>-552</td>\n",
       "      <td>25788.0</td>\n",
       "      <td>2988</td>\n",
       "      <td>23988</td>\n",
       "      <td>-559200</td>\n",
       "      <td>1341600</td>\n",
       "      <td>...</td>\n",
       "      <td>800</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6382</th>\n",
       "      <td>6383</td>\n",
       "      <td>4255</td>\n",
       "      <td>0</td>\n",
       "      <td>23242</td>\n",
       "      <td>-1883</td>\n",
       "      <td>23137.0</td>\n",
       "      <td>3037</td>\n",
       "      <td>22641</td>\n",
       "      <td>-224040</td>\n",
       "      <td>812760</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>403 rows Ã— 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      caseid  subjectid  casestart  caseend  anestart   aneend  opstart  \\\n",
       "11        12        491          0    31203      -220  31460.0     5360   \n",
       "28        29       3720          0    21394     -1176  21324.0     3324   \n",
       "51        52       1724          0    15590     -1453  15647.0     3647   \n",
       "53        54       1517          0    15346      -939  15321.0     2421   \n",
       "54        55       5077          0    21734      -722  22498.0     3598   \n",
       "...      ...        ...        ...      ...       ...      ...      ...   \n",
       "6336    6337       5565          0    24223      -449  25651.0     4051   \n",
       "6343    6344       2628          0    12168      -863  11737.0     2737   \n",
       "6345    6346       5525          0    17606      -380  17560.0     2560   \n",
       "6362    6363       5396          0    26282      -552  25788.0     2988   \n",
       "6382    6383       4255          0    23242     -1883  23137.0     3037   \n",
       "\n",
       "      opend      adm      dis  ...  intraop_colloid  intraop_ppf  intraop_mdz  \\\n",
       "11    30860  -208500  1519500  ...              200          100          0.0   \n",
       "28    20424  -114540   576660  ...                0            0          0.0   \n",
       "51    14747  -220140  1075860  ...               35            0          0.0   \n",
       "53    14421  -132240   299760  ...               35            0          0.0   \n",
       "54    21151  -210900  1603500  ...              100            0          0.0   \n",
       "...     ...      ...      ...  ...              ...          ...          ...   \n",
       "6336  23551 -1286520  1391880  ...               20            0          0.0   \n",
       "6343  10837  -114840   317160  ...                0            0          0.0   \n",
       "6345  16660  -225420   984180  ...               35            0          0.0   \n",
       "6362  23988  -559200  1341600  ...              800            0          0.0   \n",
       "6382  22641  -224040   812760  ...               35            0          0.0   \n",
       "\n",
       "     intraop_ftn  intraop_rocu  intraop_vecu  intraop_eph  intraop_phe  \\\n",
       "11           100            70             0           20            0   \n",
       "28             0           130             0            0            0   \n",
       "51             0           120             0            0            0   \n",
       "53             0            90             0           10            0   \n",
       "54             0            50             0           20            0   \n",
       "...          ...           ...           ...          ...          ...   \n",
       "6336           0             3             0            0            0   \n",
       "6343           0            70             0            0            0   \n",
       "6345           0            80             0            0            0   \n",
       "6362           0            50             0            0            0   \n",
       "6382           0            80             0           10            0   \n",
       "\n",
       "      intraop_epi intraop_ca  \n",
       "11              0       3300  \n",
       "28              0          0  \n",
       "51              0          0  \n",
       "53              0          0  \n",
       "54              0       1200  \n",
       "...           ...        ...  \n",
       "6336            0          0  \n",
       "6343            0          0  \n",
       "6345            0        300  \n",
       "6362            0          0  \n",
       "6382            0        300  \n",
       "\n",
       "[403 rows x 74 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transplantation_cases = df_cases[df_cases['optype'] == 'Transplantation']\n",
    "transplantation_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8434bacc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12,\n",
       " 29,\n",
       " 52,\n",
       " 54,\n",
       " 55,\n",
       " 58,\n",
       " 60,\n",
       " 81,\n",
       " 83,\n",
       " 97,\n",
       " 111,\n",
       " 146,\n",
       " 164,\n",
       " 177,\n",
       " 195,\n",
       " 202,\n",
       " 236,\n",
       " 237,\n",
       " 251,\n",
       " 264,\n",
       " 280,\n",
       " 284,\n",
       " 290,\n",
       " 304,\n",
       " 345,\n",
       " 349,\n",
       " 363,\n",
       " 378,\n",
       " 391,\n",
       " 397,\n",
       " 401,\n",
       " 406,\n",
       " 431,\n",
       " 448,\n",
       " 457,\n",
       " 464,\n",
       " 470,\n",
       " 507,\n",
       " 524,\n",
       " 553,\n",
       " 626,\n",
       " 631,\n",
       " 638,\n",
       " 675,\n",
       " 690,\n",
       " 691,\n",
       " 706,\n",
       " 733,\n",
       " 734,\n",
       " 741,\n",
       " 775,\n",
       " 783,\n",
       " 785,\n",
       " 814,\n",
       " 818,\n",
       " 822,\n",
       " 847,\n",
       " 870,\n",
       " 872,\n",
       " 902,\n",
       " 945,\n",
       " 964,\n",
       " 985,\n",
       " 986,\n",
       " 1018,\n",
       " 1029,\n",
       " 1042,\n",
       " 1045,\n",
       " 1056,\n",
       " 1061,\n",
       " 1083,\n",
       " 1095,\n",
       " 1157,\n",
       " 1166,\n",
       " 1168,\n",
       " 1173,\n",
       " 1191,\n",
       " 1218,\n",
       " 1229,\n",
       " 1231,\n",
       " 1284,\n",
       " 1292,\n",
       " 1325,\n",
       " 1327,\n",
       " 1350,\n",
       " 1410,\n",
       " 1454,\n",
       " 1482,\n",
       " 1512,\n",
       " 1539,\n",
       " 1545,\n",
       " 1548,\n",
       " 1564,\n",
       " 1586,\n",
       " 1590,\n",
       " 1656,\n",
       " 1683,\n",
       " 1710,\n",
       " 1716,\n",
       " 1720,\n",
       " 1724,\n",
       " 1725,\n",
       " 1730,\n",
       " 1738,\n",
       " 1762,\n",
       " 1785,\n",
       " 1807,\n",
       " 1809,\n",
       " 1820,\n",
       " 1831,\n",
       " 1835,\n",
       " 1858,\n",
       " 1885,\n",
       " 1896,\n",
       " 1900,\n",
       " 1959,\n",
       " 1964,\n",
       " 1976,\n",
       " 1983,\n",
       " 1995,\n",
       " 2014,\n",
       " 2016,\n",
       " 2047,\n",
       " 2069,\n",
       " 2096,\n",
       " 2106,\n",
       " 2130,\n",
       " 2137,\n",
       " 2160,\n",
       " 2168,\n",
       " 2185,\n",
       " 2192,\n",
       " 2202,\n",
       " 2238,\n",
       " 2245,\n",
       " 2252,\n",
       " 2267,\n",
       " 2272,\n",
       " 2273,\n",
       " 2304,\n",
       " 2320,\n",
       " 2325,\n",
       " 2326,\n",
       " 2327,\n",
       " 2331,\n",
       " 2332,\n",
       " 2337,\n",
       " 2360,\n",
       " 2375,\n",
       " 2402,\n",
       " 2453,\n",
       " 2461,\n",
       " 2489,\n",
       " 2494,\n",
       " 2512,\n",
       " 2545,\n",
       " 2558,\n",
       " 2560,\n",
       " 2593,\n",
       " 2621,\n",
       " 2626,\n",
       " 2628,\n",
       " 2667,\n",
       " 2700,\n",
       " 2715,\n",
       " 2716,\n",
       " 2722,\n",
       " 2738,\n",
       " 2751,\n",
       " 2761,\n",
       " 2764,\n",
       " 2775,\n",
       " 2821,\n",
       " 2860,\n",
       " 2872,\n",
       " 2879,\n",
       " 2945,\n",
       " 2952,\n",
       " 2954,\n",
       " 2960,\n",
       " 2963,\n",
       " 2972,\n",
       " 2985,\n",
       " 2993,\n",
       " 3024,\n",
       " 3026,\n",
       " 3093,\n",
       " 3097,\n",
       " 3101,\n",
       " 3113,\n",
       " 3121,\n",
       " 3150,\n",
       " 3188,\n",
       " 3192,\n",
       " 3196,\n",
       " 3203,\n",
       " 3237,\n",
       " 3244,\n",
       " 3248,\n",
       " 3267,\n",
       " 3270,\n",
       " 3286,\n",
       " 3287,\n",
       " 3291,\n",
       " 3300,\n",
       " 3311,\n",
       " 3321,\n",
       " 3325,\n",
       " 3380,\n",
       " 3383,\n",
       " 3392,\n",
       " 3402,\n",
       " 3468,\n",
       " 3473,\n",
       " 3478,\n",
       " 3486,\n",
       " 3493,\n",
       " 3497,\n",
       " 3505,\n",
       " 3516,\n",
       " 3524,\n",
       " 3533,\n",
       " 3537,\n",
       " 3588,\n",
       " 3593,\n",
       " 3622,\n",
       " 3625,\n",
       " 3631,\n",
       " 3652,\n",
       " 3687,\n",
       " 3694,\n",
       " 3710,\n",
       " 3719,\n",
       " 3752,\n",
       " 3753,\n",
       " 3775,\n",
       " 3791,\n",
       " 3796,\n",
       " 3818,\n",
       " 3844,\n",
       " 3870,\n",
       " 3873,\n",
       " 3875,\n",
       " 3890,\n",
       " 3904,\n",
       " 3919,\n",
       " 3930,\n",
       " 3950,\n",
       " 3989,\n",
       " 3994,\n",
       " 4005,\n",
       " 4033,\n",
       " 4034,\n",
       " 4054,\n",
       " 4090,\n",
       " 4112,\n",
       " 4125,\n",
       " 4144,\n",
       " 4151,\n",
       " 4233,\n",
       " 4246,\n",
       " 4255,\n",
       " 4258,\n",
       " 4259,\n",
       " 4271,\n",
       " 4272,\n",
       " 4282,\n",
       " 4283,\n",
       " 4299,\n",
       " 4305,\n",
       " 4310,\n",
       " 4342,\n",
       " 4386,\n",
       " 4398,\n",
       " 4417,\n",
       " 4465,\n",
       " 4475,\n",
       " 4476,\n",
       " 4481,\n",
       " 4509,\n",
       " 4510,\n",
       " 4515,\n",
       " 4535,\n",
       " 4540,\n",
       " 4558,\n",
       " 4573,\n",
       " 4574,\n",
       " 4576,\n",
       " 4578,\n",
       " 4587,\n",
       " 4599,\n",
       " 4603,\n",
       " 4609,\n",
       " 4621,\n",
       " 4649,\n",
       " 4650,\n",
       " 4651,\n",
       " 4652,\n",
       " 4684,\n",
       " 4697,\n",
       " 4721,\n",
       " 4728,\n",
       " 4731,\n",
       " 4734,\n",
       " 4744,\n",
       " 4798,\n",
       " 4800,\n",
       " 4801,\n",
       " 4806,\n",
       " 4817,\n",
       " 4824,\n",
       " 4835,\n",
       " 4851,\n",
       " 4911,\n",
       " 4932,\n",
       " 4940,\n",
       " 4947,\n",
       " 4951,\n",
       " 4959,\n",
       " 4984,\n",
       " 4987,\n",
       " 5018,\n",
       " 5036,\n",
       " 5051,\n",
       " 5088,\n",
       " 5091,\n",
       " 5127,\n",
       " 5137,\n",
       " 5175,\n",
       " 5200,\n",
       " 5222,\n",
       " 5251,\n",
       " 5262,\n",
       " 5282,\n",
       " 5290,\n",
       " 5304,\n",
       " 5349,\n",
       " 5350,\n",
       " 5370,\n",
       " 5421,\n",
       " 5425,\n",
       " 5440,\n",
       " 5442,\n",
       " 5455,\n",
       " 5459,\n",
       " 5472,\n",
       " 5550,\n",
       " 5607,\n",
       " 5618,\n",
       " 5621,\n",
       " 5622,\n",
       " 5626,\n",
       " 5637,\n",
       " 5656,\n",
       " 5669,\n",
       " 5671,\n",
       " 5682,\n",
       " 5687,\n",
       " 5693,\n",
       " 5698,\n",
       " 5750,\n",
       " 5788,\n",
       " 5806,\n",
       " 5816,\n",
       " 5820,\n",
       " 5826,\n",
       " 5837,\n",
       " 5855,\n",
       " 5859,\n",
       " 5862,\n",
       " 5878,\n",
       " 5884,\n",
       " 5898,\n",
       " 5901,\n",
       " 5907,\n",
       " 5921,\n",
       " 5954,\n",
       " 5962,\n",
       " 5964,\n",
       " 5976,\n",
       " 5983,\n",
       " 5999,\n",
       " 6009,\n",
       " 6020,\n",
       " 6037,\n",
       " 6074,\n",
       " 6075,\n",
       " 6084,\n",
       " 6110,\n",
       " 6119,\n",
       " 6126,\n",
       " 6159,\n",
       " 6177,\n",
       " 6220,\n",
       " 6227,\n",
       " 6246,\n",
       " 6292,\n",
       " 6297,\n",
       " 6337,\n",
       " 6344,\n",
       " 6346,\n",
       " 6363,\n",
       " 6383]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transplantation_caseids = transplantation_cases['caseid'].tolist()\n",
    "transplantation_caseids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81791823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ˆ Loading track data for transplantation cases...\n",
      "Found 35698 track records for 403 transplantation cases\n",
      "Unique track types available: 183\n",
      "\n",
      "ðŸ” Track categories for transplantation cases:\n",
      "\n",
      "BIS (8 tracks):\n",
      "  - BIS/BIS\n",
      "  - BIS/EEG1_WAV\n",
      "  - BIS/EEG2_WAV\n",
      "  - BIS/EMG\n",
      "  - BIS/SEF\n",
      "  - BIS/SQI\n",
      "  - BIS/SR\n",
      "  - BIS/TOTPOW\n",
      "\n",
      "CardioQ (13 tracks):\n",
      "  - CardioQ/ABP\n",
      "  - CardioQ/CI\n",
      "  - CardioQ/CO\n",
      "  - CardioQ/FLOW\n",
      "  - CardioQ/FTc\n",
      "  - CardioQ/FTp\n",
      "  - CardioQ/HR\n",
      "  - CardioQ/MA\n",
      "  - CardioQ/MD\n",
      "  - CardioQ/PV\n",
      "  - CardioQ/SD\n",
      "  - CardioQ/SV\n",
      "  - CardioQ/SVI\n",
      "\n",
      "EV1000 (9 tracks):\n",
      "  - EV1000/ART_MBP\n",
      "  - EV1000/CI\n",
      "  - EV1000/CO\n",
      "  - EV1000/CVP\n",
      "  - EV1000/SV\n",
      "  - EV1000/SVI\n",
      "  - EV1000/SVR\n",
      "  - EV1000/SVRI\n",
      "  - EV1000/SVV\n",
      "\n",
      "FMS (7 tracks):\n",
      "  - FMS/FLOW_RATE\n",
      "  - FMS/INPUT_AMB_TEMP\n",
      "  - FMS/INPUT_TEMP\n",
      "  - FMS/OUTPUT_AMB_TEMP\n",
      "  - FMS/OUTPUT_TEMP\n",
      "  - FMS/PRESSURE\n",
      "  - FMS/TOTAL_VOL\n",
      "\n",
      "Invos (2 tracks):\n",
      "  - Invos/SCO2_L\n",
      "  - Invos/SCO2_R\n",
      "\n",
      "Orchestra (39 tracks):\n",
      "  - Orchestra/DEX4_RATE\n",
      "  - Orchestra/DEX4_VOL\n",
      "  - Orchestra/DOBU_RATE\n",
      "  - Orchestra/DOBU_VOL\n",
      "  - Orchestra/DOPA_RATE\n",
      "  - Orchestra/DOPA_VOL\n",
      "  - Orchestra/EPI_RATE\n",
      "  - Orchestra/EPI_VOL\n",
      "  - Orchestra/FUT_RATE\n",
      "  - Orchestra/FUT_VOL\n",
      "  - Orchestra/MRN_RATE\n",
      "  - Orchestra/MRN_VOL\n",
      "  - Orchestra/NEPI_RATE\n",
      "  - Orchestra/NEPI_VOL\n",
      "  - Orchestra/NTG_RATE\n",
      "  - Orchestra/NTG_VOL\n",
      "  - Orchestra/PGE1_RATE\n",
      "  - Orchestra/PGE1_VOL\n",
      "  - Orchestra/PHEN_RATE\n",
      "  - Orchestra/PHEN_VOL\n",
      "  - Orchestra/PPF20_CE\n",
      "  - Orchestra/PPF20_CP\n",
      "  - Orchestra/PPF20_CT\n",
      "  - Orchestra/PPF20_RATE\n",
      "  - Orchestra/PPF20_VOL\n",
      "  - Orchestra/RFTN20_CE\n",
      "  - Orchestra/RFTN20_CP\n",
      "  - Orchestra/RFTN20_CT\n",
      "  - Orchestra/RFTN20_RATE\n",
      "  - Orchestra/RFTN20_VOL\n",
      "  - Orchestra/RFTN50_CE\n",
      "  - Orchestra/RFTN50_CP\n",
      "  - Orchestra/RFTN50_CT\n",
      "  - Orchestra/RFTN50_RATE\n",
      "  - Orchestra/RFTN50_VOL\n",
      "  - Orchestra/ROC_RATE\n",
      "  - Orchestra/ROC_VOL\n",
      "  - Orchestra/VEC_RATE\n",
      "  - Orchestra/VEC_VOL\n",
      "\n",
      "Primus (37 tracks):\n",
      "  - Primus/AWP\n",
      "  - Primus/CO2\n",
      "  - Primus/COMPLIANCE\n",
      "  - Primus/ETCO2\n",
      "  - Primus/EXP_DES\n",
      "  - Primus/EXP_SEVO\n",
      "  - Primus/FEN2O\n",
      "  - Primus/FEO2\n",
      "  - Primus/FIN2O\n",
      "  - Primus/FIO2\n",
      "  - Primus/FLOW_AIR\n",
      "  - Primus/FLOW_N2O\n",
      "  - Primus/FLOW_O2\n",
      "  - Primus/INCO2\n",
      "  - Primus/INSP_DES\n",
      "  - Primus/INSP_SEVO\n",
      "  - Primus/MAC\n",
      "  - Primus/MAWP_MBAR\n",
      "  - Primus/MV\n",
      "  - Primus/PAMB_MBAR\n",
      "  - Primus/PEEP_MBAR\n",
      "  - Primus/PIP_MBAR\n",
      "  - Primus/PPLAT_MBAR\n",
      "  - Primus/RR_CO2\n",
      "  - Primus/SET_AGE\n",
      "  - Primus/SET_FIO2\n",
      "  - Primus/SET_FLOW_TRIG\n",
      "  - Primus/SET_FRESH_FLOW\n",
      "  - Primus/SET_INSP_PAUSE\n",
      "  - Primus/SET_INSP_PRES\n",
      "  - Primus/SET_INSP_TM\n",
      "  - Primus/SET_INTER_PEEP\n",
      "  - Primus/SET_PIP\n",
      "  - Primus/SET_RR_IPPV\n",
      "  - Primus/SET_TV_L\n",
      "  - Primus/TV\n",
      "  - Primus/VENT_LEAK\n",
      "\n",
      "SNUADC (6 tracks):\n",
      "  - SNUADC/ART\n",
      "  - SNUADC/CVP\n",
      "  - SNUADC/ECG_II\n",
      "  - SNUADC/ECG_V5\n",
      "  - SNUADC/FEM\n",
      "  - SNUADC/PLETH\n",
      "\n",
      "Solar8000 (43 tracks):\n",
      "  - Solar8000/ART_DBP\n",
      "  - Solar8000/ART_MBP\n",
      "  - Solar8000/ART_SBP\n",
      "  - Solar8000/BT\n",
      "  - Solar8000/CVP\n",
      "  - Solar8000/ETCO2\n",
      "  - Solar8000/FEM_DBP\n",
      "  - Solar8000/FEM_MBP\n",
      "  - Solar8000/FEM_SBP\n",
      "  - Solar8000/FEO2\n",
      "  - Solar8000/FIO2\n",
      "  - Solar8000/GAS2_EXPIRED\n",
      "  - Solar8000/GAS2_INSPIRED\n",
      "  - Solar8000/HR\n",
      "  - Solar8000/INCO2\n",
      "  - Solar8000/NIBP_DBP\n",
      "  - Solar8000/NIBP_MBP\n",
      "  - Solar8000/NIBP_SBP\n",
      "  - Solar8000/PA_DBP\n",
      "  - Solar8000/PA_MBP\n",
      "  - Solar8000/PA_SBP\n",
      "  - Solar8000/PLETH_HR\n",
      "  - Solar8000/PLETH_SPO2\n",
      "  - Solar8000/RR\n",
      "  - Solar8000/RR_CO2\n",
      "  - Solar8000/ST_AVF\n",
      "  - Solar8000/ST_AVL\n",
      "  - Solar8000/ST_AVR\n",
      "  - Solar8000/ST_I\n",
      "  - Solar8000/ST_II\n",
      "  - Solar8000/ST_III\n",
      "  - Solar8000/VENT_COMPL\n",
      "  - Solar8000/VENT_INSP_TM\n",
      "  - Solar8000/VENT_MAWP\n",
      "  - Solar8000/VENT_MEAS_PEEP\n",
      "  - Solar8000/VENT_MV\n",
      "  - Solar8000/VENT_PIP\n",
      "  - Solar8000/VENT_PPLAT\n",
      "  - Solar8000/VENT_RR\n",
      "  - Solar8000/VENT_SET_FIO2\n",
      "  - Solar8000/VENT_SET_PCP\n",
      "  - Solar8000/VENT_SET_TV\n",
      "  - Solar8000/VENT_TV\n",
      "\n",
      "Vigilance (14 tracks):\n",
      "  - Vigilance/BT_PA\n",
      "  - Vigilance/CI\n",
      "  - Vigilance/CO\n",
      "  - Vigilance/EDV\n",
      "  - Vigilance/EDVI\n",
      "  - Vigilance/ESV\n",
      "  - Vigilance/ESVI\n",
      "  - Vigilance/HR_AVG\n",
      "  - Vigilance/RVEF\n",
      "  - Vigilance/SNR\n",
      "  - Vigilance/SQI\n",
      "  - Vigilance/SV\n",
      "  - Vigilance/SVI\n",
      "  - Vigilance/SVO2\n",
      "\n",
      "Vigileo (5 tracks):\n",
      "  - Vigileo/CI\n",
      "  - Vigileo/CO\n",
      "  - Vigileo/SV\n",
      "  - Vigileo/SVI\n",
      "  - Vigileo/SVV\n",
      "\n",
      "ðŸ“Š Most common tracks for transplantation cases:\n",
      "  - Solar8000/PLETH_HR: 403 cases (100.0%)\n",
      "  - Solar8000/PLETH_SPO2: 403 cases (100.0%)\n",
      "  - Solar8000/HR: 403 cases (100.0%)\n",
      "  - Primus/FIN2O: 402 cases (99.8%)\n",
      "  - Primus/ETCO2: 402 cases (99.8%)\n",
      "  - Primus/CO2: 402 cases (99.8%)\n",
      "  - Primus/FEN2O: 402 cases (99.8%)\n",
      "  - Primus/PAMB_MBAR: 402 cases (99.8%)\n",
      "  - Primus/SET_FIO2: 402 cases (99.8%)\n",
      "  - Primus/SET_AGE: 402 cases (99.8%)\n",
      "  - Primus/RR_CO2: 402 cases (99.8%)\n",
      "  - Primus/MAC: 402 cases (99.8%)\n",
      "  - Primus/MAWP_MBAR: 402 cases (99.8%)\n",
      "  - SNUADC/ECG_II: 402 cases (99.8%)\n",
      "  - Primus/SET_FRESH_FLOW: 402 cases (99.8%)\n"
     ]
    }
   ],
   "source": [
    "# Load track data for transplantation cases\n",
    "print(\"ðŸ“ˆ Loading track data for transplantation cases...\")\n",
    "\n",
    "# Get tracks available for transplantation cases\n",
    "transplantation_tracks = df_trks[df_trks['caseid'].isin(transplantation_caseids)]\n",
    "print(f\"Found {len(transplantation_tracks)} track records for {len(transplantation_caseids)} transplantation cases\")\n",
    "print(f\"Unique track types available: {transplantation_tracks['tname'].nunique()}\")\n",
    "\n",
    "# Show track categories for transplantation cases\n",
    "print(\"\\nðŸ” Track categories for transplantation cases:\")\n",
    "track_categories = {}\n",
    "for track in transplantation_tracks['tname'].unique():\n",
    "    device = track.split('/')[0] if '/' in track else 'Unknown'\n",
    "    if device not in track_categories:\n",
    "        track_categories[device] = []\n",
    "    track_categories[device].append(track)\n",
    "\n",
    "for device, tracks in sorted(track_categories.items()):\n",
    "    print(f\"\\n{device} ({len(tracks)} tracks):\")\n",
    "    for track in sorted(tracks):\n",
    "        print(f\"  - {track}\")\n",
    "\n",
    "# Show most common tracks for transplantation cases\n",
    "print(f\"\\nðŸ“Š Most common tracks for transplantation cases:\")\n",
    "track_counts = transplantation_tracks['tname'].value_counts().head(15)\n",
    "for track, count in track_counts.items():\n",
    "    percentage = (count / len(transplantation_caseids)) * 100\n",
    "    print(f\"  - {track}: {count} cases ({percentage:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2613092e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Loading lab data for transplantation cases...\n",
      "Found 193144 lab records for transplantation cases\n",
      "Unique lab types available: 34\n",
      "\n",
      "ðŸ”¬ Lab types for transplantation cases:\n",
      "  - hct: 11573 records (2871.7% of cases)\n",
      "  - k: 10706 records (2656.6% of cases)\n",
      "  - na: 10703 records (2655.8% of cases)\n",
      "  - hb: 8769 records (2175.9% of cases)\n",
      "  - wbc: 8753 records (2172.0% of cases)\n",
      "  - plt: 8665 records (2150.1% of cases)\n",
      "  - gluc: 8398 records (2083.9% of cases)\n",
      "  - cl: 7872 records (1953.3% of cases)\n",
      "  - alb: 7841 records (1945.7% of cases)\n",
      "  - cr: 7679 records (1905.5% of cases)\n",
      "  - bun: 7661 records (1901.0% of cases)\n",
      "  - tprot: 7654 records (1899.3% of cases)\n",
      "  - tbil: 7559 records (1875.7% of cases)\n",
      "  - ast: 7523 records (1866.7% of cases)\n",
      "  - alt: 7521 records (1866.3% of cases)\n",
      "  - gfr: 7369 records (1828.5% of cases)\n",
      "  - ptinr: 5580 records (1384.6% of cases)\n",
      "  - ptsec: 5580 records (1384.6% of cases)\n",
      "  - pt%: 5579 records (1384.4% of cases)\n",
      "  - aptt: 5173 records (1283.6% of cases)\n",
      "  - fib: 4698 records (1165.8% of cases)\n",
      "  - crp: 4077 records (1011.7% of cases)\n",
      "  - ica: 3982 records (988.1% of cases)\n",
      "  - p: 3208 records (796.0% of cases)\n",
      "  - ph: 2830 records (702.2% of cases)\n",
      "  - po2: 2829 records (702.0% of cases)\n",
      "  - pco2: 2826 records (701.2% of cases)\n",
      "  - lac: 2818 records (699.3% of cases)\n",
      "  - hco3: 2815 records (698.5% of cases)\n",
      "  - sao2: 2813 records (698.0% of cases)\n",
      "  - be: 772 records (191.6% of cases)\n",
      "  - ammo: 522 records (129.5% of cases)\n",
      "  - ccr: 451 records (111.9% of cases)\n",
      "  - esr: 345 records (85.6% of cases)\n",
      "\n",
      "ðŸ«€ Key organ function tests for transplantation cases:\n",
      "  - ast: 7523 records (1866.7% of cases)\n",
      "  - alt: 7521 records (1866.3% of cases)\n",
      "  - tbil: 7559 records (1875.7% of cases)\n",
      "  - alb: 7841 records (1945.7% of cases)\n",
      "  - tprot: 7654 records (1899.3% of cases)\n",
      "  - ptsec: 5580 records (1384.6% of cases)\n",
      "  - ptinr: 5580 records (1384.6% of cases)\n",
      "  - aptt: 5173 records (1283.6% of cases)\n",
      "  - fib: 4698 records (1165.8% of cases)\n",
      "\n",
      "ðŸ§ª Basic metabolic panel for transplantation cases:\n",
      "  - na: 10703 records (2655.8% of cases)\n",
      "  - k: 10706 records (2656.6% of cases)\n",
      "  - cl: 7872 records (1953.3% of cases)\n",
      "  - cr: 7679 records (1905.5% of cases)\n",
      "  - bun: 7661 records (1901.0% of cases)\n",
      "  - gfr: 7369 records (1828.5% of cases)\n",
      "  - gluc: 8398 records (2083.9% of cases)\n"
     ]
    }
   ],
   "source": [
    "# Load lab data for transplantation cases\n",
    "print(\"ðŸ§ª Loading lab data for transplantation cases...\")\n",
    "\n",
    "# Get lab results for transplantation cases\n",
    "transplantation_labs = df_labs[df_labs['caseid'].isin(transplantation_caseids)]\n",
    "print(f\"Found {len(transplantation_labs)} lab records for transplantation cases\")\n",
    "print(f\"Unique lab types available: {transplantation_labs['name'].nunique()}\")\n",
    "\n",
    "# Show lab types and their frequency for transplantation cases\n",
    "print(f\"\\nðŸ”¬ Lab types for transplantation cases:\")\n",
    "lab_counts = transplantation_labs['name'].value_counts()\n",
    "for lab, count in lab_counts.items():\n",
    "    percentage = (count / len(transplantation_caseids)) * 100\n",
    "    print(f\"  - {lab}: {count} records ({percentage:.1f}% of cases)\")\n",
    "\n",
    "# Show key organ function tests\n",
    "print(f\"\\nðŸ«€ Key organ function tests for transplantation cases:\")\n",
    "organ_function_tests = ['ast', 'alt', 'tbil', 'alb', 'tprot', 'ptsec', 'ptinr', 'aptt', 'fib']\n",
    "for test in organ_function_tests:\n",
    "    if test in transplantation_labs['name'].values:\n",
    "        count = (transplantation_labs['name'] == test).sum()\n",
    "        percentage = (count / len(transplantation_caseids)) * 100\n",
    "        print(f\"  - {test}: {count} records ({percentage:.1f}% of cases)\")\n",
    "    else:\n",
    "        print(f\"  - {test}: Not available\")\n",
    "\n",
    "# Show basic metabolic panel\n",
    "print(f\"\\nðŸ§ª Basic metabolic panel for transplantation cases:\")\n",
    "metabolic_tests = ['na', 'k', 'cl', 'cr', 'bun', 'gfr', 'gluc']\n",
    "for test in metabolic_tests:\n",
    "    if test in transplantation_labs['name'].values:\n",
    "        count = (transplantation_labs['name'] == test).sum()\n",
    "        percentage = (count / len(transplantation_caseids)) * 100\n",
    "        print(f\"  - {test}: {count} records ({percentage:.1f}% of cases)\")\n",
    "    else:\n",
    "        print(f\"  - {test}: Not available\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b7780cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vitaldb\n",
      "  Downloading vitaldb-1.5.8-py3-none-any.whl.metadata (314 bytes)\n",
      "Requirement already satisfied: numpy in c:\\users\\cherish\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from vitaldb) (2.3.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\cherish\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from vitaldb) (2.3.3)\n",
      "Collecting requests (from vitaldb)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting wfdb (from vitaldb)\n",
      "  Downloading wfdb-4.3.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\cherish\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from pandas->vitaldb) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\cherish\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from pandas->vitaldb) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\cherish\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from pandas->vitaldb) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cherish\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->vitaldb) (1.17.0)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->vitaldb)\n",
      "  Using cached charset_normalizer-3.4.4-cp314-cp314-win_amd64.whl.metadata (38 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->vitaldb)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->vitaldb)\n",
      "  Downloading urllib3-2.6.2-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->vitaldb)\n",
      "  Using cached certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting aiohttp>=3.10.11 (from wfdb->vitaldb)\n",
      "  Using cached aiohttp-3.13.2-cp314-cp314-win_amd64.whl.metadata (8.4 kB)\n",
      "Collecting fsspec>=2023.10.0 (from wfdb->vitaldb)\n",
      "  Downloading fsspec-2025.12.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: matplotlib>=3.2.2 in c:\\users\\cherish\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from wfdb->vitaldb) (3.10.7)\n",
      "Requirement already satisfied: scipy>=1.13.0 in c:\\users\\cherish\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from wfdb->vitaldb) (1.16.3)\n",
      "Collecting soundfile>=0.10.0 (from wfdb->vitaldb)\n",
      "  Downloading soundfile-0.13.1-py2.py3-none-win_amd64.whl.metadata (16 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp>=3.10.11->wfdb->vitaldb)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp>=3.10.11->wfdb->vitaldb)\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp>=3.10.11->wfdb->vitaldb)\n",
      "  Using cached attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp>=3.10.11->wfdb->vitaldb)\n",
      "  Using cached frozenlist-1.8.0-cp314-cp314-win_amd64.whl.metadata (21 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp>=3.10.11->wfdb->vitaldb)\n",
      "  Using cached multidict-6.7.0-cp314-cp314-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp>=3.10.11->wfdb->vitaldb)\n",
      "  Using cached propcache-0.4.1-cp314-cp314-win_amd64.whl.metadata (14 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp>=3.10.11->wfdb->vitaldb)\n",
      "  Using cached yarl-1.22.0-cp314-cp314-win_amd64.whl.metadata (77 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\cherish\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from matplotlib>=3.2.2->wfdb->vitaldb) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\cherish\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from matplotlib>=3.2.2->wfdb->vitaldb) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\cherish\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from matplotlib>=3.2.2->wfdb->vitaldb) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\cherish\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from matplotlib>=3.2.2->wfdb->vitaldb) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\cherish\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from matplotlib>=3.2.2->wfdb->vitaldb) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\cherish\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from matplotlib>=3.2.2->wfdb->vitaldb) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\cherish\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from matplotlib>=3.2.2->wfdb->vitaldb) (3.2.5)\n",
      "Collecting cffi>=1.0 (from soundfile>=0.10.0->wfdb->vitaldb)\n",
      "  Downloading cffi-2.0.0-cp314-cp314-win_amd64.whl.metadata (2.6 kB)\n",
      "Collecting pycparser (from cffi>=1.0->soundfile>=0.10.0->wfdb->vitaldb)\n",
      "  Downloading pycparser-2.23-py3-none-any.whl.metadata (993 bytes)\n",
      "Downloading vitaldb-1.5.8-py3-none-any.whl (60 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.4-cp314-cp314-win_amd64.whl (107 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Downloading urllib3-2.6.2-py3-none-any.whl (131 kB)\n",
      "Using cached certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "Downloading wfdb-4.3.0-py3-none-any.whl (163 kB)\n",
      "Using cached aiohttp-3.13.2-cp314-cp314-win_amd64.whl (457 kB)\n",
      "Using cached multidict-6.7.0-cp314-cp314-win_amd64.whl (45 kB)\n",
      "Using cached yarl-1.22.0-cp314-cp314-win_amd64.whl (88 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Using cached frozenlist-1.8.0-cp314-cp314-win_amd64.whl (44 kB)\n",
      "Downloading fsspec-2025.12.0-py3-none-any.whl (201 kB)\n",
      "Using cached propcache-0.4.1-cp314-cp314-win_amd64.whl (41 kB)\n",
      "Downloading soundfile-0.13.1-py2.py3-none-win_amd64.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 6.6 MB/s  0:00:00\n",
      "Downloading cffi-2.0.0-cp314-cp314-win_amd64.whl (185 kB)\n",
      "Downloading pycparser-2.23-py3-none-any.whl (118 kB)\n",
      "Installing collected packages: urllib3, pycparser, propcache, multidict, idna, fsspec, frozenlist, charset_normalizer, certifi, attrs, aiohappyeyeballs, yarl, requests, cffi, aiosignal, soundfile, aiohttp, wfdb, vitaldb\n",
      "\n",
      "   ----------------------------------------  0/19 [urllib3]\n",
      "   -- -------------------------------------  1/19 [pycparser]\n",
      "   ---- -----------------------------------  2/19 [propcache]\n",
      "   -------- -------------------------------  4/19 [idna]\n",
      "   ---------- -----------------------------  5/19 [fsspec]\n",
      "   ---------- -----------------------------  5/19 [fsspec]\n",
      "   ------------------ ---------------------  9/19 [attrs]\n",
      "   ------------------------- -------------- 12/19 [requests]\n",
      "   --------------------------- ------------ 13/19 [cffi]\n",
      "   --------------------------------- ------ 16/19 [aiohttp]\n",
      "   --------------------------------- ------ 16/19 [aiohttp]\n",
      "   --------------------------------- ------ 16/19 [aiohttp]\n",
      "   ----------------------------------- ---- 17/19 [wfdb]\n",
      "   ---------------------------------------- 19/19 [vitaldb]\n",
      "\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 attrs-25.4.0 certifi-2025.11.12 cffi-2.0.0 charset_normalizer-3.4.4 frozenlist-1.8.0 fsspec-2025.12.0 idna-3.11 multidict-6.7.0 propcache-0.4.1 pycparser-2.23 requests-2.32.5 soundfile-0.13.1 urllib3-2.6.2 vitaldb-1.5.8 wfdb-4.3.0 yarl-1.22.0\n"
     ]
    }
   ],
   "source": [
    "!pip install vitaldb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b0bec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Loading waveform data for transplantation cases...\n",
      "Available tracks: 183 types\n",
      "Key tracks available: 10\n",
      "Available key tracks:\n",
      "  - Solar8000/HR\n",
      "  - Solar8000/ART_SBP\n",
      "  - Solar8000/ART_DBP\n",
      "  - Solar8000/ART_MBP\n",
      "  - Solar8000/PLETH_SPO2\n",
      "  - SNUADC/ART\n",
      "  - SNUADC/ECG_II\n",
      "  - Primus/CO2\n",
      "  - Primus/ETCO2\n",
      "  - BIS/BIS\n",
      "\n",
      "ðŸ“Š Loading waveform data for transplantation case 12...\n",
      "âœ… Successfully loaded waveform data!\n",
      "  - Data shape: (3120291, 10)\n",
      "  - Time points: 3120291\n",
      "  - Tracks: 10\n",
      "\n",
      "ðŸ“ˆ Data availability for each track:\n",
      "  - Solar8000/HR: 15482/3120291 (0.5%)\n",
      "  - Solar8000/ART_SBP: 13858/3120291 (0.4%)\n",
      "  - Solar8000/ART_DBP: 13861/3120291 (0.4%)\n",
      "  - Solar8000/ART_MBP: 14346/3120291 (0.5%)\n",
      "  - Solar8000/PLETH_SPO2: 15473/3120291 (0.5%)\n",
      "  - SNUADC/ART: 2255264/3120291 (72.3%)\n",
      "  - SNUADC/ECG_II: 2255264/3120291 (72.3%)\n",
      "  - Primus/CO2: 3117940/3120291 (99.9%)\n",
      "  - Primus/ETCO2: 4313/3120291 (0.1%)\n",
      "  - BIS/BIS: 31184/3120291 (1.0%)\n"
     ]
    }
   ],
   "source": [
    "# Load waveform data for transplantation cases using vitaldb\n",
    "import vitaldb\n",
    "\n",
    "print(\"ðŸ”„ Loading waveform data for transplantation cases...\")\n",
    "\n",
    "# Get available track names for transplantation cases\n",
    "available_tracks = transplantation_tracks['tname'].unique().tolist()\n",
    "print(f\"Available tracks: {len(available_tracks)} types\")\n",
    "\n",
    "# Select key tracks for transplantation surgery monitoring\n",
    "key_tracks = [\n",
    "    'Solar8000/HR',           # Heart rate\n",
    "    'Solar8000/ART_SBP',      # Systolic blood pressure  \n",
    "    'Solar8000/ART_DBP',      # Diastolic blood pressure\n",
    "    'Solar8000/ART_MBP',      # Mean blood pressure\n",
    "    'Solar8000/PLETH_SPO2',   # Oxygen saturation\n",
    "    'SNUADC/ART',             # Arterial pressure waveform\n",
    "    'SNUADC/ECG_II',          # ECG Lead II\n",
    "    'Primus/CO2',             # CO2 monitoring\n",
    "    'Primus/ETCO2',           # End-tidal CO2\n",
    "    'BIS/BIS'                 # Bispectral index\n",
    "]\n",
    "\n",
    "# Filter to only tracks that are available for transplantation cases\n",
    "available_key_tracks = [track for track in key_tracks if track in available_tracks]\n",
    "print(f\"Key tracks available: {len(available_key_tracks)}\")\n",
    "\n",
    "if len(available_key_tracks) > 0:\n",
    "    print(\"Available key tracks:\")\n",
    "    for track in available_key_tracks:\n",
    "        print(f\"  - {track}\")\n",
    "        \n",
    "    # Load waveform data for first transplantation case as example\n",
    "    if len(transplantation_caseids) > 0:\n",
    "        example_case_id = transplantation_caseids[0]\n",
    "        print(f\"\\nðŸ“Š Loading waveform data for transplantation case {example_case_id}...\")\n",
    "        \n",
    "        try:\n",
    "            # Load waveform data\n",
    "            waveform_data = vitaldb.load_case(\n",
    "                caseid=example_case_id,\n",
    "                track_names=available_key_tracks,\n",
    "                interval=1.0  # 1Hz sampling rate (consistent with training data)\n",
    "            )\n",
    "            \n",
    "            print(f\"âœ… Successfully loaded waveform data!\")\n",
    "            print(f\"  - Data shape: {waveform_data.shape}\")\n",
    "            print(f\"  - Time points: {waveform_data.shape[0]}\")\n",
    "            print(f\"  - Tracks: {waveform_data.shape[1]}\")\n",
    "            \n",
    "            # Show data availability for each track\n",
    "            print(\"\\nðŸ“ˆ Data availability for each track:\")\n",
    "            for i, track_name in enumerate(available_key_tracks):\n",
    "                track_data = waveform_data[:, i]\n",
    "                non_nan_count = np.sum(~np.isnan(track_data))\n",
    "                total_count = len(track_data)\n",
    "                availability = (non_nan_count / total_count) * 100\n",
    "                print(f\"  - {track_name}: {non_nan_count}/{total_count} ({availability:.1f}%)\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error loading waveform data: {e}\")\n",
    "else:\n",
    "    print(\"âŒ No key tracks available for transplantation cases\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "905931e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‹ TRANSPLANTATION CASES DATA SUMMARY\n",
      "==================================================\n",
      "\n",
      "ðŸ¥ CASES:\n",
      "  - Total transplantation cases: 403\n",
      "  - Case IDs: [12, 29, 52, 54, 55, 58, 60, 81, 83, 97]...\n",
      "\n",
      "ðŸ“ˆ WAVEFORMS:\n",
      "  - Total track records: 35698\n",
      "  - Unique track types: 183\n",
      "  - Track categories: 11\n",
      "\n",
      "ðŸ§ª LAB RESULTS:\n",
      "  - Total lab records: 193144\n",
      "  - Unique lab types: 34\n",
      "\n",
      "ðŸŽ¯ KEY INSIGHTS FOR TRANSPLANTATION SURGERY:\n",
      "  - Cardiovascular monitoring: Heart rate, blood pressure, ECG\n",
      "  - Respiratory monitoring: CO2, oxygen saturation, ventilation\n",
      "  - Neurological monitoring: BIS index, EEG\n",
      "  - Organ function tests: AST, ALT, bilirubin, albumin, PT/INR\n",
      "  - Metabolic panel: Electrolytes, creatinine, glucose\n",
      "  - Coagulation studies: PT, PTT, fibrinogen\n",
      "\n",
      "âœ… Ready for real-time transplantation vital forecasting and anomaly detection!\n",
      "   - 403 cases available\n",
      "   - 183 waveform types\n",
      "   - 34 lab result types\n"
     ]
    }
   ],
   "source": [
    "# Create a comprehensive data summary for transplantation cases\n",
    "print(\"ðŸ“‹ TRANSPLANTATION CASES DATA SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\nðŸ¥ CASES:\")\n",
    "print(f\"  - Total transplantation cases: {len(transplantation_cases)}\")\n",
    "print(f\"  - Case IDs: {transplantation_caseids[:10]}...\" if len(transplantation_caseids) > 10 else f\"  - Case IDs: {transplantation_caseids}\")\n",
    "\n",
    "print(f\"\\nðŸ“ˆ WAVEFORMS:\")\n",
    "print(f\"  - Total track records: {len(transplantation_tracks)}\")\n",
    "print(f\"  - Unique track types: {transplantation_tracks['tname'].nunique()}\")\n",
    "print(f\"  - Track categories: {len(track_categories)}\")\n",
    "\n",
    "print(f\"\\nðŸ§ª LAB RESULTS:\")\n",
    "print(f\"  - Total lab records: {len(transplantation_labs)}\")\n",
    "print(f\"  - Unique lab types: {transplantation_labs['name'].nunique()}\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ KEY INSIGHTS FOR TRANSPLANTATION SURGERY:\")\n",
    "print(\"  - Cardiovascular monitoring: Heart rate, blood pressure, ECG\")\n",
    "print(\"  - Respiratory monitoring: CO2, oxygen saturation, ventilation\")\n",
    "print(\"  - Neurological monitoring: BIS index, EEG\")\n",
    "print(\"  - Organ function tests: AST, ALT, bilirubin, albumin, PT/INR\")\n",
    "print(\"  - Metabolic panel: Electrolytes, creatinine, glucose\")\n",
    "print(\"  - Coagulation studies: PT, PTT, fibrinogen\")\n",
    "\n",
    "print(f\"\\nâœ… Ready for real-time transplantation vital forecasting and anomaly detection!\")\n",
    "print(f\"   - {len(transplantation_caseids)} cases available\")\n",
    "print(f\"   - {transplantation_tracks['tname'].nunique()} waveform types\")\n",
    "print(f\"   - {transplantation_labs['name'].nunique()} lab result types\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593831eb",
   "metadata": {},
   "source": [
    "## Data Quality Analysis for BP Forecasting\n",
    "\n",
    "Analyze track availability and data completeness to identify transplantation cases suitable for blood pressure forecasting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f626414f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Analyzing data quality for BP forecasting...\n",
      "\n",
      "ðŸ“Š Track Availability Summary:\n",
      "  - Cases with MBP track: 316 / 403 (78.4%)\n",
      "  - Cases with HR track: 403 / 403 (100.0%)\n",
      "  - Cases with SpO2 track: 403 / 403 (100.0%)\n",
      "  - Cases with ETCO2 track: 402 / 403 (99.8%)\n",
      "  - Cases with BIS track: 387 / 403 (96.0%)\n",
      "\n",
      "ðŸ“ˆ Feature Availability:\n",
      "  - Cases with 0 features: 0\n",
      "  - Cases with 1-2 features: 0\n",
      "  - Cases with 3-4 features: 403\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caseid</th>\n",
       "      <th>has_mbp</th>\n",
       "      <th>has_sbp</th>\n",
       "      <th>has_dbp</th>\n",
       "      <th>has_hr</th>\n",
       "      <th>has_spo2</th>\n",
       "      <th>has_etco2</th>\n",
       "      <th>has_bis</th>\n",
       "      <th>available_tracks</th>\n",
       "      <th>feature_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>96</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>89</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>94</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>76</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>58</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>84</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>60</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>98</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>81</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>78</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>83</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>97</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>96</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   caseid  has_mbp  has_sbp  has_dbp  has_hr  has_spo2  has_etco2  has_bis  \\\n",
       "0      12     True     True     True    True      True       True     True   \n",
       "1      29     True     True     True    True      True       True     True   \n",
       "2      52     True     True     True    True      True       True     True   \n",
       "3      54    False    False    False    True      True       True     True   \n",
       "4      55     True     True     True    True      True       True     True   \n",
       "5      58     True     True     True    True      True       True     True   \n",
       "6      60     True     True     True    True      True       True     True   \n",
       "7      81    False    False    False    True      True       True     True   \n",
       "8      83     True     True     True    True      True       True     True   \n",
       "9      97     True     True     True    True      True       True     True   \n",
       "\n",
       "   available_tracks  feature_count  \n",
       "0                96              4  \n",
       "1                89              4  \n",
       "2                94              4  \n",
       "3                76              4  \n",
       "4               113              4  \n",
       "5                84              4  \n",
       "6                98              4  \n",
       "7                78              4  \n",
       "8                93              4  \n",
       "9                96              4  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Quality Analysis for BP Forecasting\n",
    "print(\"ðŸ” Analyzing data quality for BP forecasting...\")\n",
    "\n",
    "# Define BP-related tracks and feature tracks\n",
    "bp_tracks = {\n",
    "    'target': ['Solar8000/ART_MBP'],  # Mean Blood Pressure (target)\n",
    "    'bp_related': ['Solar8000/ART_SBP', 'Solar8000/ART_DBP', 'SNUADC/ART'],\n",
    "    'features': ['Solar8000/HR', 'Solar8000/PLETH_SPO2', 'Primus/ETCO2', 'BIS/BIS']\n",
    "}\n",
    "\n",
    "# Analyze track availability for each transplantation case\n",
    "case_quality = []\n",
    "\n",
    "for caseid in transplantation_caseids:\n",
    "    case_tracks = transplantation_tracks[transplantation_tracks['caseid'] == caseid]['tname'].tolist()\n",
    "    \n",
    "    quality_metrics = {\n",
    "        'caseid': caseid,\n",
    "        'has_mbp': 'Solar8000/ART_MBP' in case_tracks,\n",
    "        'has_sbp': 'Solar8000/ART_SBP' in case_tracks,\n",
    "        'has_dbp': 'Solar8000/ART_DBP' in case_tracks,\n",
    "        'has_hr': 'Solar8000/HR' in case_tracks,\n",
    "        'has_spo2': 'Solar8000/PLETH_SPO2' in case_tracks,\n",
    "        'has_etco2': 'Primus/ETCO2' in case_tracks,\n",
    "        'has_bis': 'BIS/BIS' in case_tracks,\n",
    "        'available_tracks': len(case_tracks)\n",
    "    }\n",
    "    \n",
    "    # Count available feature tracks\n",
    "    feature_count = sum([\n",
    "        quality_metrics['has_hr'],\n",
    "        quality_metrics['has_spo2'],\n",
    "        quality_metrics['has_etco2'],\n",
    "        quality_metrics['has_bis']\n",
    "    ])\n",
    "    quality_metrics['feature_count'] = feature_count\n",
    "    \n",
    "    case_quality.append(quality_metrics)\n",
    "\n",
    "quality_df = pd.DataFrame(case_quality)\n",
    "\n",
    "print(f\"\\nðŸ“Š Track Availability Summary:\")\n",
    "print(f\"  - Cases with MBP track: {quality_df['has_mbp'].sum()} / {len(quality_df)} ({quality_df['has_mbp'].sum()/len(quality_df)*100:.1f}%)\")\n",
    "print(f\"  - Cases with HR track: {quality_df['has_hr'].sum()} / {len(quality_df)} ({quality_df['has_hr'].sum()/len(quality_df)*100:.1f}%)\")\n",
    "print(f\"  - Cases with SpO2 track: {quality_df['has_spo2'].sum()} / {len(quality_df)} ({quality_df['has_spo2'].sum()/len(quality_df)*100:.1f}%)\")\n",
    "print(f\"  - Cases with ETCO2 track: {quality_df['has_etco2'].sum()} / {len(quality_df)} ({quality_df['has_etco2'].sum()/len(quality_df)*100:.1f}%)\")\n",
    "print(f\"  - Cases with BIS track: {quality_df['has_bis'].sum()} / {len(quality_df)} ({quality_df['has_bis'].sum()/len(quality_df)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nðŸ“ˆ Feature Availability:\")\n",
    "print(f\"  - Cases with 0 features: {(quality_df['feature_count'] == 0).sum()}\")\n",
    "print(f\"  - Cases with 1-2 features: {((quality_df['feature_count'] >= 1) & (quality_df['feature_count'] <= 2)).sum()}\")\n",
    "print(f\"  - Cases with 3-4 features: {((quality_df['feature_count'] >= 3) & (quality_df['feature_count'] <= 4)).sum()}\")\n",
    "\n",
    "quality_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38062e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Checking data completeness for cases with MBP track...\n",
      "Found 316 cases with MBP track\n",
      "\n",
      "âœ… Data completeness analysis for 20 cases:\n",
      "  - Mean completeness: 49.6%\n",
      "  - Mean duration: 356.1 minutes\n",
      "  - Cases with >80% completeness: 0\n",
      "  - Cases with >30 minutes: 20\n",
      "\n",
      "âœ… Cases suitable for forecasting: 0\n"
     ]
    }
   ],
   "source": [
    "# Numba-optimized function for calculating data completeness\n",
    "@jit(nopython=True)\n",
    "def calculate_completeness_numba(data_array):\n",
    "    \"\"\"\n",
    "    Calculate completeness percentage for a data array.\n",
    "    Optimized with numba for faster computation.\n",
    "    \"\"\"\n",
    "    total = len(data_array)\n",
    "    non_nan = 0\n",
    "    for i in prange(total):\n",
    "        if not np.isnan(data_array[i]):\n",
    "            non_nan += 1\n",
    "    return (non_nan / total * 100.0) if total > 0 else 0.0\n",
    "\n",
    "# Load sample data to check data completeness\n",
    "print(\"ðŸ“Š Checking data completeness for cases with MBP track...\")\n",
    "\n",
    "mbp_cases = quality_df[quality_df['has_mbp'] == True]['caseid'].tolist()\n",
    "print(f\"Found {len(mbp_cases)} cases with MBP track\")\n",
    "\n",
    "# Check data completeness for a sample of cases\n",
    "completeness_results = []\n",
    "\n",
    "# Sample first 20 cases to check completeness (to avoid long runtime)\n",
    "sample_cases = mbp_cases[:20] if len(mbp_cases) > 20 else mbp_cases\n",
    "\n",
    "for caseid in sample_cases:\n",
    "    try:\n",
    "        # Load MBP data at 1Hz (1 second intervals)\n",
    "        mbp_data = vitaldb.load_case(\n",
    "            caseid=caseid,\n",
    "            track_names=['Solar8000/ART_MBP'],\n",
    "            interval=1.0  # 1Hz sampling\n",
    "        )\n",
    "        \n",
    "        if mbp_data is not None and mbp_data.shape[0] > 0:\n",
    "            mbp_values = mbp_data[:, 0].astype(np.float64)\n",
    "            # Use numba-optimized function\n",
    "            completeness = calculate_completeness_numba(mbp_values)\n",
    "            total_count = len(mbp_values)\n",
    "            non_nan_count = int(total_count * completeness / 100.0)\n",
    "            duration_minutes = total_count / 60.0  # Convert seconds to minutes\n",
    "            \n",
    "            completeness_results.append({\n",
    "                'caseid': caseid,\n",
    "                'completeness': completeness,\n",
    "                'duration_minutes': duration_minutes,\n",
    "                'non_nan_count': non_nan_count,\n",
    "                'total_count': total_count\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"  âš ï¸ Error loading case {caseid}: {e}\")\n",
    "        continue\n",
    "\n",
    "if completeness_results:\n",
    "    completeness_df = pd.DataFrame(completeness_results)\n",
    "    print(f\"\\nâœ… Data completeness analysis for {len(completeness_df)} cases:\")\n",
    "    print(f\"  - Mean completeness: {completeness_df['completeness'].mean():.1f}%\")\n",
    "    print(f\"  - Mean duration: {completeness_df['duration_minutes'].mean():.1f} minutes\")\n",
    "    print(f\"  - Cases with >20% completeness: {(completeness_df['completeness'] > 20).sum()}\")\n",
    "    print(f\"  - Cases with >2 minutes: {(completeness_df['duration_minutes'] > 2).sum()}\")\n",
    "    \n",
    "    # Filter cases with good data quality (relaxed criteria)\n",
    "    # Lower threshold: >20% completeness and >2 minutes duration (sufficient for 90s minimum)\n",
    "    good_cases = completeness_df[\n",
    "        (completeness_df['completeness'] > 20) & \n",
    "        (completeness_df['duration_minutes'] > 2)\n",
    "    ]['caseid'].tolist()\n",
    "    \n",
    "    print(f\"\\nâœ… Cases suitable for forecasting: {len(good_cases)}\")\n",
    "    completeness_df.head(10)\n",
    "else:\n",
    "    print(\"âŒ No completeness data available\")\n",
    "    good_cases = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92e83eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‹ Filtered cases for BP forecasting:\n",
      "  - Total transplantation cases: 403\n",
      "  - Cases with MBP track: 316\n",
      "  - Cases with MBP + 2+ features: 316\n",
      "  - Selected cases: 316\n",
      "\n",
      "âœ… Final filtered case IDs: [12, 29, 52, 55, 58, 60, 83, 97, 111, 146]...\n"
     ]
    }
   ],
   "source": [
    "# Filter transplantation cases for forecasting\n",
    "# Use cases with MBP track and at least 2 feature tracks\n",
    "filtered_cases = quality_df[\n",
    "    (quality_df['has_mbp'] == True) & \n",
    "    (quality_df['feature_count'] >= 2)\n",
    "]['caseid'].tolist()\n",
    "\n",
    "print(f\"ðŸ“‹ Filtered cases for BP forecasting:\")\n",
    "print(f\"  - Total transplantation cases: {len(transplantation_caseids)}\")\n",
    "print(f\"  - Cases with MBP track: {quality_df['has_mbp'].sum()}\")\n",
    "print(f\"  - Cases with MBP + 2+ features: {len(filtered_cases)}\")\n",
    "print(f\"  - Selected cases: {len(filtered_cases)}\")\n",
    "\n",
    "# If we have completeness data, further filter\n",
    "if 'good_cases' in locals() and len(good_cases) > 0:\n",
    "    # Intersect with good quality cases\n",
    "    filtered_cases = [c for c in filtered_cases if c in good_cases]\n",
    "    print(f\"  - After quality filtering: {len(filtered_cases)} cases\")\n",
    "\n",
    "print(f\"\\nâœ… Final filtered case IDs: {filtered_cases[:10]}...\" if len(filtered_cases) > 10 else f\"\\nâœ… Final filtered case IDs: {filtered_cases}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828748d1",
   "metadata": {},
   "source": [
    "## Load Waveform Data and Export to CSV\n",
    "\n",
    "Load waveform data for filtered transplantation cases and export to CSV for BP forecasting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f17d10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¥ Loading waveform data for filtered transplantation cases...\n",
      "Processing 316 cases...\n",
      "  Processing case 10/316...\n",
      "  Processing case 20/316...\n",
      "  Processing case 30/316...\n",
      "  Processing case 40/316...\n",
      "  Processing case 50/316...\n",
      "  Processing case 60/316...\n",
      "  Processing case 70/316...\n",
      "  Processing case 80/316...\n",
      "  Processing case 90/316...\n",
      "  Processing case 100/316...\n",
      "  Processing case 110/316...\n",
      "  Processing case 120/316...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     35\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# Load waveform data at 1Hz (1 second intervals)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m waveform_data = \u001b[43mvitaldb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_case\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcaseid\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcaseid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrack_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtracks_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterval\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 1Hz sampling rate\u001b[39;49;00m\n\u001b[32m     42\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m waveform_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m waveform_data.shape[\u001b[32m0\u001b[39m] == \u001b[32m0\u001b[39m:\n\u001b[32m     45\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CHERISH\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\vitaldb\\dataset.py:171\u001b[39m, in \u001b[36mload_case\u001b[39m\u001b[34m(caseid, track_names, interval)\u001b[39m\n\u001b[32m    169\u001b[39m tids = []\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m dtname \u001b[38;5;129;01min\u001b[39;00m track_names:\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m     tid_values = dftrks.loc[(dftrks[\u001b[33m'\u001b[39m\u001b[33mcaseid\u001b[39m\u001b[33m'\u001b[39m] == caseid) & (\u001b[43mdftrks\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtname\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mendswith\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtname\u001b[49m\u001b[43m)\u001b[49m), \u001b[33m'\u001b[39m\u001b[33mtid\u001b[39m\u001b[33m'\u001b[39m].values\n\u001b[32m    172\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tid_values):\n\u001b[32m    173\u001b[39m         tids.append(tid_values[\u001b[32m0\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CHERISH\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\core\\strings\\accessor.py:140\u001b[39m, in \u001b[36mforbid_nonstring_types.<locals>._forbid_nonstring_types.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    135\u001b[39m     msg = (\n\u001b[32m    136\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot use .str.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with values of \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    137\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33minferred dtype \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m._inferred_dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    138\u001b[39m     )\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CHERISH\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\core\\strings\\accessor.py:2581\u001b[39m, in \u001b[36mStringMethods.endswith\u001b[39m\u001b[34m(self, pat, na)\u001b[39m\n\u001b[32m   2579\u001b[39m     msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mexpected a string or tuple, not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(pat).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   2580\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m-> \u001b[39m\u001b[32m2581\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_str_endswith\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2582\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._wrap_result(result, returns_string=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CHERISH\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\core\\strings\\object_array.py:186\u001b[39m, in \u001b[36mObjectStringArrayMixin._str_endswith\u001b[39m\u001b[34m(self, pat, na)\u001b[39m\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib.no_default \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m isna(na) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(na, \u001b[38;5;28mbool\u001b[39m):\n\u001b[32m    179\u001b[39m     \u001b[38;5;66;03m# GH#59561\u001b[39;00m\n\u001b[32m    180\u001b[39m     warnings.warn(\n\u001b[32m    181\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAllowing a non-bool \u001b[39m\u001b[33m'\u001b[39m\u001b[33mna\u001b[39m\u001b[33m'\u001b[39m\u001b[33m in obj.str.endswith is deprecated \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    182\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mand will raise in a future version.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    183\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    184\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    185\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_str_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CHERISH\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\core\\strings\\object_array.py:80\u001b[39m, in \u001b[36mObjectStringArrayMixin._str_map\u001b[39m\u001b[34m(self, f, na_value, dtype, convert)\u001b[39m\n\u001b[32m     78\u001b[39m arr = np.asarray(\u001b[38;5;28mself\u001b[39m, dtype=\u001b[38;5;28mobject\u001b[39m)\n\u001b[32m     79\u001b[39m mask = isna(arr)\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m map_convert = convert \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     82\u001b[39m     result = lib.map_infer_mask(arr, f, mask.view(np.uint8), map_convert)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CHERISH\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:2584\u001b[39m, in \u001b[36m_all_dispatcher\u001b[39m\u001b[34m(a, axis, out, keepdims, where)\u001b[39m\n\u001b[32m   2479\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2480\u001b[39m \u001b[33;03m    Test whether any array element along a given axis evaluates to True.\u001b[39;00m\n\u001b[32m   2481\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   2578\u001b[39m \n\u001b[32m   2579\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   2580\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapreduction_any_all(a, np.logical_or, \u001b[33m'\u001b[39m\u001b[33many\u001b[39m\u001b[33m'\u001b[39m, axis, out,\n\u001b[32m   2581\u001b[39m                                   keepdims=keepdims, where=where)\n\u001b[32m-> \u001b[39m\u001b[32m2584\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_all_dispatcher\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=\u001b[38;5;28;01mNone\u001b[39;00m, *,\n\u001b[32m   2585\u001b[39m                     where=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   2586\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (a, where, out)\n\u001b[32m   2589\u001b[39m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_all_dispatcher)\n\u001b[32m   2590\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mall\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=np._NoValue, *, where=np._NoValue):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Batch load waveform data for filtered cases\n",
    "print(\"ðŸ“¥ Loading waveform data for filtered transplantation cases...\")\n",
    "print(f\"Processing {len(filtered_cases)} cases...\")\n",
    "\n",
    "# Define tracks to load (MBP as target, others as features)\n",
    "tracks_to_load = {\n",
    "    'mbp': 'Solar8000/ART_MBP',\n",
    "    'hr': 'Solar8000/HR',\n",
    "    'spo2': 'Solar8000/PLETH_SPO2',\n",
    "    'etco2': 'Primus/ETCO2',\n",
    "    'bis': 'BIS/BIS'\n",
    "}\n",
    "\n",
    "# Get available tracks for each case\n",
    "all_data = []\n",
    "\n",
    "for idx, caseid in enumerate(filtered_cases):\n",
    "    if (idx + 1) % 10 == 0:\n",
    "        print(f\"  Processing case {idx + 1}/{len(filtered_cases)}...\")\n",
    "    \n",
    "    try:\n",
    "        # Get available tracks for this case\n",
    "        case_tracks = transplantation_tracks[transplantation_tracks['caseid'] == caseid]['tname'].tolist()\n",
    "        \n",
    "        # Build list of tracks to load (only if available)\n",
    "        tracks_list = []\n",
    "        track_mapping = {}  # Map track name to column index\n",
    "        \n",
    "        for key, track_name in tracks_to_load.items():\n",
    "            if track_name in case_tracks:\n",
    "                tracks_list.append(track_name)\n",
    "                track_mapping[track_name] = key\n",
    "        \n",
    "        if len(tracks_list) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Load waveform data at 1Hz (1 second intervals)\n",
    "        waveform_data = vitaldb.load_case(\n",
    "            caseid=caseid,\n",
    "            track_names=tracks_list,\n",
    "            interval=1.0  # 1Hz sampling rate\n",
    "        )\n",
    "        \n",
    "        if waveform_data is None or waveform_data.shape[0] == 0:\n",
    "            continue\n",
    "        \n",
    "        # Create DataFrame for this case\n",
    "        case_df = pd.DataFrame()\n",
    "        case_df['caseid'] = caseid\n",
    "        case_df['timestamp'] = np.arange(len(waveform_data))  # Time in seconds\n",
    "        \n",
    "        # Add each track as a column\n",
    "        for i, track_name in enumerate(tracks_list):\n",
    "            column_name = track_mapping[track_name]\n",
    "            case_df[column_name] = waveform_data[:, i]\n",
    "        \n",
    "        all_data.append(case_df)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  âš ï¸ Error loading case {caseid}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\nâœ… Successfully loaded data from {len(all_data)} cases\")\n",
    "\n",
    "# Combine all cases into single DataFrame\n",
    "if len(all_data) > 0:\n",
    "    combined_data = pd.concat(all_data, ignore_index=True)\n",
    "    print(f\"\\nðŸ“Š Combined dataset:\")\n",
    "    print(f\"  - Total rows: {len(combined_data)}\")\n",
    "    print(f\"  - Columns: {list(combined_data.columns)}\")\n",
    "    print(f\"  - Memory usage: {combined_data.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    \n",
    "    # Show data availability\n",
    "    print(f\"\\nðŸ“ˆ Data availability:\")\n",
    "    for col in ['mbp', 'hr', 'spo2', 'etco2', 'bis']:\n",
    "        if col in combined_data.columns:\n",
    "            non_nan = combined_data[col].notna().sum()\n",
    "            total = len(combined_data)\n",
    "            print(f\"  - {col.upper()}: {non_nan}/{total} ({non_nan/total*100:.1f}%)\")\n",
    "    \n",
    "    combined_data.head()\n",
    "else:\n",
    "    print(\"âŒ No data loaded\")\n",
    "    combined_data = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b7d7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numba-optimized forward/backward fill\n",
    "@jit(nopython=True)\n",
    "def forward_backward_fill_numba(data_array):\n",
    "    \"\"\"\n",
    "    Forward fill then backward fill for a 1D array.\n",
    "    Optimized with numba for faster computation.\n",
    "    \"\"\"\n",
    "    n = len(data_array)\n",
    "    result = data_array.copy()\n",
    "    \n",
    "    # Forward fill\n",
    "    last_valid = np.nan\n",
    "    for i in range(n):\n",
    "        if not np.isnan(result[i]):\n",
    "            last_valid = result[i]\n",
    "        else:\n",
    "            result[i] = last_valid\n",
    "    \n",
    "    # Backward fill\n",
    "    last_valid = np.nan\n",
    "    for i in range(n - 1, -1, -1):\n",
    "        if not np.isnan(result[i]):\n",
    "            last_valid = result[i]\n",
    "        else:\n",
    "            result[i] = last_valid\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Handle missing data with forward fill and interpolation\n",
    "print(\"ðŸ”§ Processing missing data...\")\n",
    "\n",
    "if len(combined_data) > 0:\n",
    "    # Forward fill missing values (within each case)\n",
    "    processed_data = combined_data.copy()\n",
    "    \n",
    "    # Group by caseid and forward fill\n",
    "    for caseid in processed_data['caseid'].unique():\n",
    "        case_mask = processed_data['caseid'] == caseid\n",
    "        case_data = processed_data.loc[case_mask].copy()\n",
    "        \n",
    "        # Forward fill, then backward fill for each column using numba\n",
    "        for col in ['mbp', 'hr', 'spo2', 'etco2', 'bis']:\n",
    "            if col in case_data.columns:\n",
    "                # Convert to numpy array for numba processing\n",
    "                col_array = case_data[col].values.astype(np.float64)\n",
    "                filled_array = forward_backward_fill_numba(col_array)\n",
    "                case_data[col] = filled_array\n",
    "                processed_data.loc[case_mask, col] = filled_array\n",
    "    \n",
    "    # Remove rows where MBP is still NaN (critical for target variable)\n",
    "    initial_rows = len(processed_data)\n",
    "    processed_data = processed_data[processed_data['mbp'].notna()]\n",
    "    removed_rows = initial_rows - len(processed_data)\n",
    "    \n",
    "    print(f\"  - Removed {removed_rows} rows with missing MBP\")\n",
    "    print(f\"  - Remaining rows: {len(processed_data)}\")\n",
    "    \n",
    "    # Show final data availability\n",
    "    print(f\"\\nðŸ“ˆ Final data availability after processing:\")\n",
    "    for col in ['mbp', 'hr', 'spo2', 'etco2', 'bis']:\n",
    "        if col in processed_data.columns:\n",
    "            non_nan = processed_data[col].notna().sum()\n",
    "            total = len(processed_data)\n",
    "            print(f\"  - {col.upper()}: {non_nan}/{total} ({non_nan/total*100:.1f}%)\")\n",
    "    \n",
    "    processed_data.head(10)\n",
    "else:\n",
    "    processed_data = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7111c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV\n",
    "import os\n",
    "\n",
    "if len(processed_data) > 0:\n",
    "    output_file = 'transplantation_bp_data.csv'\n",
    "    processed_data.to_csv(output_file, index=False)\n",
    "    print(f\"âœ… Data exported to {output_file}\")\n",
    "    print(f\"  - Total rows: {len(processed_data)}\")\n",
    "    print(f\"  - Unique cases: {processed_data['caseid'].nunique()}\")\n",
    "    if os.path.exists(output_file):\n",
    "        print(f\"  - File size: {os.path.getsize(output_file) / 1024**2:.2f} MB\")\n",
    "    \n",
    "    # Create metadata summary\n",
    "    metadata = {\n",
    "        'total_cases': processed_data['caseid'].nunique(),\n",
    "        'total_rows': len(processed_data),\n",
    "        'sampling_rate_hz': 1.0,\n",
    "        'tracks_included': list(processed_data.columns),\n",
    "        'case_ids': processed_data['caseid'].unique().tolist(),\n",
    "        'date_created': pd.Timestamp.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nðŸ“‹ Metadata:\")\n",
    "    print(f\"  - Cases: {metadata['total_cases']}\")\n",
    "    print(f\"  - Sampling rate: {metadata['sampling_rate_hz']} Hz\")\n",
    "    print(f\"  - Columns: {', '.join(metadata['tracks_included'])}\")\n",
    "else:\n",
    "    print(\"âŒ No data to export\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feab2877",
   "metadata": {},
   "source": [
    "## Time Series Preprocessing for LSTM\n",
    "\n",
    "Prepare data for LSTM forecasting: normalization, sliding windows, and train/val/test split.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242b48fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numba-optimized normalization helper\n",
    "@jit(nopython=True)\n",
    "def normalize_array_numba(data_array):\n",
    "    \"\"\"\n",
    "    Normalize array using z-score (mean=0, std=1).\n",
    "    Returns normalized array, mean, and std.\n",
    "    \"\"\"\n",
    "    n = len(data_array)\n",
    "    mean = 0.0\n",
    "    std = 0.0\n",
    "    \n",
    "    # Calculate mean\n",
    "    valid_count = 0\n",
    "    for i in range(n):\n",
    "        if not np.isnan(data_array[i]):\n",
    "            mean += data_array[i]\n",
    "            valid_count += 1\n",
    "    if valid_count > 0:\n",
    "        mean = mean / valid_count\n",
    "    \n",
    "    # Calculate std\n",
    "    for i in range(n):\n",
    "        if not np.isnan(data_array[i]):\n",
    "            diff = data_array[i] - mean\n",
    "            std += diff * diff\n",
    "    if valid_count > 0:\n",
    "        std = np.sqrt(std / valid_count)\n",
    "    \n",
    "    # Normalize\n",
    "    normalized = np.zeros(n, dtype=np.float64)\n",
    "    for i in range(n):\n",
    "        if not np.isnan(data_array[i]) and std > 1e-8:\n",
    "            normalized[i] = (data_array[i] - mean) / std\n",
    "        else:\n",
    "            normalized[i] = data_array[i]\n",
    "    \n",
    "    return normalized, mean, std\n",
    "\n",
    "# Load the exported data\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "if os.path.exists('transplantation_bp_data.csv'):\n",
    "    data = pd.read_csv('transplantation_bp_data.csv')\n",
    "    print(f\"âœ… Loaded data: {len(data)} rows, {data['caseid'].nunique()} cases\")\n",
    "else:\n",
    "    print(\"âŒ CSV file not found. Please run previous cells first.\")\n",
    "    data = pd.DataFrame()\n",
    "\n",
    "if len(data) > 0:\n",
    "    print(f\"\\nðŸ“Š Data summary:\")\n",
    "    print(f\"  - Cases: {data['caseid'].nunique()}\")\n",
    "    print(f\"  - Columns: {list(data.columns)}\")\n",
    "    print(f\"  - Date range per case: {data.groupby('caseid')['timestamp'].agg(['min', 'max', 'count']).head()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac387d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing parameters\n",
    "SEQ_LENGTH = 60  # 1 minute at 1Hz (input sequence) - 60 past values\n",
    "FORECAST_HORIZON = 30  # 30 seconds at 1Hz (forecast horizon) - forecast 30s ahead\n",
    "FEATURE_COLS = ['mbp', 'hr', 'spo2', 'etco2', 'bis']  # Features to use\n",
    "\n",
    "print(f\"âš™ï¸ Preprocessing configuration:\")\n",
    "print(f\"  - Input sequence length: {SEQ_LENGTH} seconds ({SEQ_LENGTH/60:.1f} minutes)\")\n",
    "print(f\"  - Forecast horizon: {FORECAST_HORIZON} seconds ({FORECAST_HORIZON/60:.1f} minutes)\")\n",
    "print(f\"  - Features: {FEATURE_COLS}\")\n",
    "\n",
    "# Filter to only cases with sufficient data\n",
    "if len(data) > 0:\n",
    "    # Calculate minimum required length per case\n",
    "    min_length = SEQ_LENGTH + FORECAST_HORIZON\n",
    "    \n",
    "    case_lengths = data.groupby('caseid').size()\n",
    "    valid_cases = case_lengths[case_lengths >= min_length].index.tolist()\n",
    "    \n",
    "    print(f\"\\nðŸ“‹ Case filtering:\")\n",
    "    print(f\"  - Total cases: {data['caseid'].nunique()}\")\n",
    "    print(f\"  - Cases with sufficient data (>{min_length} seconds): {len(valid_cases)}\")\n",
    "    \n",
    "    # Filter data to valid cases\n",
    "    data_filtered = data[data['caseid'].isin(valid_cases)].copy()\n",
    "    print(f\"  - Filtered data rows: {len(data_filtered)}\")\n",
    "    \n",
    "    # Separate features and target\n",
    "    available_features = [col for col in FEATURE_COLS if col in data_filtered.columns]\n",
    "    print(f\"  - Available features: {available_features}\")\n",
    "    \n",
    "    # Normalize features (per case to avoid data leakage)\n",
    "    # Use numba-optimized normalization for better performance\n",
    "    scalers = {}\n",
    "    normalized_data = data_filtered.copy()\n",
    "    \n",
    "    for caseid in valid_cases:\n",
    "        case_mask = normalized_data['caseid'] == caseid\n",
    "        case_data = normalized_data.loc[case_mask, available_features].copy()\n",
    "        \n",
    "        # Use numba-optimized normalization for each feature\n",
    "        scaled_values = case_data.values.copy().astype(np.float64)\n",
    "        n_features = scaled_values.shape[1]\n",
    "        \n",
    "        for feat_idx in range(n_features):\n",
    "            feat_array = scaled_values[:, feat_idx]\n",
    "            normalized_feat, mean_val, std_val = normalize_array_numba(feat_array)\n",
    "            scaled_values[:, feat_idx] = normalized_feat\n",
    "        \n",
    "        normalized_data.loc[case_mask, available_features] = scaled_values\n",
    "        \n",
    "        # Store scaler info (for denormalization later)\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(case_data.values)\n",
    "        scalers[caseid] = scaler\n",
    "    \n",
    "    print(f\"âœ… Normalized data for {len(valid_cases)} cases\")\n",
    "    normalized_data.head()\n",
    "else:\n",
    "    normalized_data = pd.DataFrame()\n",
    "    valid_cases = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1baaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numba-optimized sequence creation helper\n",
    "@jit(nopython=True)\n",
    "def create_sequences_numba(feature_data, target_data, seq_length, forecast_horizon):\n",
    "    \"\"\"\n",
    "    Create sequences from numpy arrays (numba-optimized).\n",
    "    feature_data: (n_samples, n_features) array\n",
    "    target_data: (n_samples,) array\n",
    "    \"\"\"\n",
    "    n_samples = len(feature_data)\n",
    "    n_features = feature_data.shape[1]\n",
    "    min_length = seq_length + forecast_horizon\n",
    "    \n",
    "    if n_samples < min_length:\n",
    "        return None, None\n",
    "    \n",
    "    max_sequences = n_samples - min_length + 1\n",
    "    sequences = np.zeros((max_sequences, seq_length, n_features), dtype=np.float64)\n",
    "    targets = np.zeros(max_sequences, dtype=np.float64)\n",
    "    valid_count = 0\n",
    "    \n",
    "    for i in range(n_samples - min_length + 1):\n",
    "        # Extract sequence\n",
    "        for j in range(seq_length):\n",
    "            for k in range(n_features):\n",
    "                sequences[valid_count, j, k] = feature_data[i + j, k]\n",
    "        \n",
    "        # Extract target\n",
    "        target_idx = i + seq_length + forecast_horizon - 1\n",
    "        targets[valid_count] = target_data[target_idx]\n",
    "        valid_count += 1\n",
    "    \n",
    "    return sequences[:valid_count], targets[:valid_count]\n",
    "\n",
    "# Create sliding windows for LSTM (optimized version)\n",
    "def create_sequences(data, caseid_col, feature_cols, target_col, seq_length, forecast_horizon):\n",
    "    \"\"\"\n",
    "    Create input sequences and target values for time series forecasting.\n",
    "    Uses numba-optimized helper for faster processing.\n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    case_ids = []\n",
    "    \n",
    "    for caseid in data[caseid_col].unique():\n",
    "        case_data = data[data[caseid_col] == caseid].sort_values('timestamp').reset_index(drop=True)\n",
    "        \n",
    "        # Need at least seq_length + forecast_horizon data points\n",
    "        if len(case_data) < seq_length + forecast_horizon:\n",
    "            continue\n",
    "        \n",
    "        # Convert to numpy arrays for numba processing\n",
    "        feature_array = case_data[feature_cols].values.astype(np.float64)\n",
    "        target_array = case_data[target_col].values.astype(np.float64)\n",
    "        \n",
    "        # Use numba-optimized function\n",
    "        case_sequences, case_targets = create_sequences_numba(\n",
    "            feature_array, target_array, seq_length, forecast_horizon\n",
    "        )\n",
    "        \n",
    "        if case_sequences is not None and len(case_sequences) > 0:\n",
    "            sequences.append(case_sequences)\n",
    "            targets.append(case_targets)\n",
    "            case_ids.extend([caseid] * len(case_targets))\n",
    "    \n",
    "    if len(sequences) > 0:\n",
    "        return np.vstack(sequences), np.concatenate(targets), np.array(case_ids)\n",
    "    else:\n",
    "        return np.array([]), np.array([]), np.array([])\n",
    "\n",
    "if len(normalized_data) > 0:\n",
    "    print(\"ðŸ”„ Creating sequences...\")\n",
    "    \n",
    "    # Create sequences\n",
    "    X, y, case_ids = create_sequences(\n",
    "        normalized_data,\n",
    "        caseid_col='caseid',\n",
    "        feature_cols=available_features,\n",
    "        target_col='mbp',\n",
    "        seq_length=SEQ_LENGTH,\n",
    "        forecast_horizon=FORECAST_HORIZON\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… Created sequences:\")\n",
    "    print(f\"  - Input shape: {X.shape}\")\n",
    "    print(f\"  - Target shape: {y.shape}\")\n",
    "    print(f\"  - Unique cases: {len(np.unique(case_ids))}\")\n",
    "    \n",
    "    # Split by case ID to avoid data leakage\n",
    "    unique_cases = np.unique(case_ids)\n",
    "    np.random.seed(42)\n",
    "    np.random.shuffle(unique_cases)\n",
    "    \n",
    "    train_split = int(0.7 * len(unique_cases))\n",
    "    val_split = int(0.85 * len(unique_cases))\n",
    "    \n",
    "    train_cases = unique_cases[:train_split]\n",
    "    val_cases = unique_cases[train_split:val_split]\n",
    "    test_cases = unique_cases[val_split:]\n",
    "    \n",
    "    # Create masks\n",
    "    train_mask = np.isin(case_ids, train_cases)\n",
    "    val_mask = np.isin(case_ids, val_cases)\n",
    "    test_mask = np.isin(case_ids, test_cases)\n",
    "    \n",
    "    X_train, y_train = X[train_mask], y[train_mask]\n",
    "    X_val, y_val = X[val_mask], y[val_mask]\n",
    "    X_test, y_test = X[test_mask], y[test_mask]\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Train/Val/Test split:\")\n",
    "    print(f\"  - Train: {len(X_train)} sequences from {len(train_cases)} cases\")\n",
    "    print(f\"  - Val: {len(X_val)} sequences from {len(val_cases)} cases\")\n",
    "    print(f\"  - Test: {len(X_test)} sequences from {len(test_cases)} cases\")\n",
    "    \n",
    "    print(f\"\\nâœ… Data ready for LSTM training!\")\n",
    "else:\n",
    "    print(\"âŒ No data available for sequence creation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c17f76e",
   "metadata": {},
   "source": [
    "## Build LSTM Model for BP Forecasting\n",
    "\n",
    "Create a multi-layer LSTM model to forecast Mean Blood Pressure 30 seconds ahead.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dcbace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LSTM model\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "print(\"ðŸ—ï¸ Building LSTM model...\")\n",
    "\n",
    "if len(X_train) > 0:\n",
    "    # Model parameters\n",
    "    lstm_units = 128\n",
    "    dropout_rate = 0.2\n",
    "    learning_rate = 0.001\n",
    "    \n",
    "    # Get input dimensions\n",
    "    n_features = X_train.shape[2]\n",
    "    seq_length = X_train.shape[1]\n",
    "    \n",
    "    print(f\"  - Input shape: (batch, {seq_length}, {n_features})\")\n",
    "    print(f\"  - LSTM units: {lstm_units}\")\n",
    "    print(f\"  - Dropout: {dropout_rate}\")\n",
    "    print(f\"  - Learning rate: {learning_rate}\")\n",
    "    \n",
    "    # Build model\n",
    "    model = keras.Sequential([\n",
    "        # First LSTM layer\n",
    "        layers.LSTM(lstm_units, return_sequences=True, input_shape=(seq_length, n_features)),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        \n",
    "        # Second LSTM layer\n",
    "        layers.LSTM(lstm_units, return_sequences=True),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        \n",
    "        # Third LSTM layer\n",
    "        layers.LSTM(lstm_units // 2, return_sequences=False),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        \n",
    "        # Dense output layer\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        layers.Dense(1)  # Single output: MBP forecast\n",
    "    ])\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss='mean_absolute_error',  # MAE for BP forecasting\n",
    "        metrics=['mean_squared_error', 'mean_absolute_error']\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nâœ… Model built successfully!\")\n",
    "    print(f\"\\nðŸ“‹ Model architecture:\")\n",
    "    model.summary()\n",
    "else:\n",
    "    print(\"âŒ No training data available\")\n",
    "    model = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c113d546",
   "metadata": {},
   "source": [
    "## Train LSTM Model\n",
    "\n",
    "Train the model with early stopping and checkpointing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75af6193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "if model is not None and len(X_train) > 0:\n",
    "    print(\"ðŸš€ Training LSTM model...\")\n",
    "    \n",
    "    # Callbacks\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    checkpoint = ModelCheckpoint(\n",
    "        'lstm_bp_model.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Training parameters\n",
    "    batch_size = 32\n",
    "    epochs = 50\n",
    "    \n",
    "    print(f\"  - Batch size: {batch_size}\")\n",
    "    print(f\"  - Max epochs: {epochs}\")\n",
    "    print(f\"  - Early stopping patience: 10\")\n",
    "    \n",
    "    # Train model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        callbacks=[early_stopping, checkpoint],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nâœ… Training completed!\")\n",
    "    print(f\"  - Best validation loss: {min(history.history['val_loss']):.4f}\")\n",
    "    print(f\"  - Best validation MAE: {min(history.history['val_mean_absolute_error']):.4f}\")\n",
    "    \n",
    "    # Plot training history\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    # Loss plot\n",
    "    axes[0].plot(history.history['loss'], label='Train Loss')\n",
    "    axes[0].plot(history.history['val_loss'], label='Val Loss')\n",
    "    axes[0].set_title('Model Loss')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss (MAE)')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "    \n",
    "    # MAE plot\n",
    "    axes[1].plot(history.history['mean_absolute_error'], label='Train MAE')\n",
    "    axes[1].plot(history.history['val_mean_absolute_error'], label='Val MAE')\n",
    "    axes[1].set_title('Mean Absolute Error')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('MAE')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Training history saved to training_history.png\")\n",
    "else:\n",
    "    print(\"âŒ Model not available for training\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c91317c",
   "metadata": {},
   "source": [
    "## Generate Forecasts and Evaluate\n",
    "\n",
    "Generate 30-second ahead MBP forecasts for test cases and calculate evaluation metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b03505f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numba-optimized metric calculations\n",
    "@jit(nopython=True)\n",
    "def calculate_mae_numba(y_true, y_pred):\n",
    "    \"\"\"Calculate Mean Absolute Error (numba-optimized).\"\"\"\n",
    "    n = len(y_true)\n",
    "    mae = 0.0\n",
    "    for i in prange(n):\n",
    "        mae += np.abs(y_true[i] - y_pred[i])\n",
    "    return mae / n\n",
    "\n",
    "@jit(nopython=True)\n",
    "def calculate_rmse_numba(y_true, y_pred):\n",
    "    \"\"\"Calculate Root Mean Squared Error (numba-optimized).\"\"\"\n",
    "    n = len(y_true)\n",
    "    mse = 0.0\n",
    "    for i in prange(n):\n",
    "        diff = y_true[i] - y_pred[i]\n",
    "        mse += diff * diff\n",
    "    return np.sqrt(mse / n)\n",
    "\n",
    "@jit(nopython=True)\n",
    "def calculate_mape_numba(y_true, y_pred):\n",
    "    \"\"\"Calculate Mean Absolute Percentage Error (numba-optimized).\"\"\"\n",
    "    n = len(y_true)\n",
    "    mape = 0.0\n",
    "    for i in prange(n):\n",
    "        if np.abs(y_true[i]) > 1e-8:\n",
    "            mape += np.abs((y_true[i] - y_pred[i]) / y_true[i])\n",
    "    return (mape / n) * 100.0\n",
    "\n",
    "# Generate forecasts on test set\n",
    "if model is not None and len(X_test) > 0:\n",
    "    print(\"ðŸ”® Generating forecasts...\")\n",
    "    \n",
    "    # Predict on test set\n",
    "    y_pred = model.predict(X_test, verbose=0)\n",
    "    y_pred = y_pred.flatten()\n",
    "    \n",
    "    # Convert to numpy arrays for numba\n",
    "    y_test_array = y_test.astype(np.float64)\n",
    "    y_pred_array = y_pred.astype(np.float64)\n",
    "    \n",
    "    # Calculate metrics using numba-optimized functions\n",
    "    mae = calculate_mae_numba(y_test_array, y_pred_array)\n",
    "    rmse = calculate_rmse_numba(y_test_array, y_pred_array)\n",
    "    mape = calculate_mape_numba(y_test_array, y_pred_array)\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Test Set Metrics:\")\n",
    "    print(f\"  - MAE: {mae:.4f}\")\n",
    "    print(f\"  - RMSE: {rmse:.4f}\")\n",
    "    print(f\"  - MAPE: {mape:.2f}%\")\n",
    "    \n",
    "    # Denormalize predictions (need to use scalers from training)\n",
    "    # For simplicity, we'll use the mean and std from test set\n",
    "    # In production, you'd use the scalers saved during training\n",
    "    test_mbp_mean = normalized_data[normalized_data['caseid'].isin(test_cases)]['mbp'].mean()\n",
    "    test_mbp_std = normalized_data[normalized_data['caseid'].isin(test_cases)]['mbp'].std()\n",
    "    \n",
    "    # Get original MBP values from data\n",
    "    test_original_mbp = []\n",
    "    test_predicted_mbp = []\n",
    "    \n",
    "    # Reconstruct original values per case\n",
    "    for caseid in test_cases:\n",
    "        case_data = normalized_data[normalized_data['caseid'] == caseid].sort_values('timestamp')\n",
    "        if len(case_data) >= SEQ_LENGTH + FORECAST_HORIZON:\n",
    "            # Get the actual MBP values at forecast points\n",
    "            case_indices = np.where(case_ids[test_mask] == caseid)[0]\n",
    "            if len(case_indices) > 0:\n",
    "                # Get original MBP from data\n",
    "                forecast_points = [SEQ_LENGTH + FORECAST_HORIZON - 1 + i * FORECAST_HORIZON \n",
    "                                  for i in range(len(case_indices))]\n",
    "                forecast_points = [p for p in forecast_points if p < len(case_data)]\n",
    "                \n",
    "                if len(forecast_points) > 0:\n",
    "                    actual_mbp = case_data.iloc[forecast_points[:len(case_indices)]]['mbp'].values\n",
    "                    pred_mbp = y_pred[case_indices[:len(actual_mbp)]]\n",
    "                    \n",
    "                    test_original_mbp.extend(actual_mbp)\n",
    "                    test_predicted_mbp.extend(pred_mbp)\n",
    "    \n",
    "    if len(test_original_mbp) > 0:\n",
    "        test_original_mbp = np.array(test_original_mbp)\n",
    "        test_predicted_mbp = np.array(test_predicted_mbp)\n",
    "        \n",
    "        # Denormalize (approximate - in production use saved scalers)\n",
    "        # We'll use the overall statistics as approximation\n",
    "        original_mean = data[data['caseid'].isin(test_cases)]['mbp'].mean()\n",
    "        original_std = data[data['caseid'].isin(test_cases)]['mbp'].std()\n",
    "        \n",
    "        denorm_actual = test_original_mbp * original_std + original_mean\n",
    "        denorm_pred = test_predicted_mbp * original_std + original_mean\n",
    "        \n",
    "        # Calculate denormalized metrics using numba-optimized functions\n",
    "        denorm_actual_array = denorm_actual.astype(np.float64)\n",
    "        denorm_pred_array = denorm_pred.astype(np.float64)\n",
    "        denorm_mae = calculate_mae_numba(denorm_actual_array, denorm_pred_array)\n",
    "        denorm_rmse = calculate_rmse_numba(denorm_actual_array, denorm_pred_array)\n",
    "        denorm_mape = calculate_mape_numba(denorm_actual_array, denorm_pred_array)\n",
    "        \n",
    "        print(f\"\\nðŸ“Š Denormalized Metrics (mmHg):\")\n",
    "        print(f\"  - MAE: {denorm_mae:.2f} mmHg\")\n",
    "        print(f\"  - RMSE: {denorm_rmse:.2f} mmHg\")\n",
    "        print(f\"  - MAPE: {denorm_mape:.2f}%\")\n",
    "        \n",
    "        # Store for visualization\n",
    "        forecast_results = {\n",
    "            'actual': denorm_actual,\n",
    "            'predicted': denorm_pred\n",
    "        }\n",
    "    else:\n",
    "        forecast_results = None\n",
    "        print(\"âš ï¸ Could not denormalize predictions\")\n",
    "else:\n",
    "    print(\"âŒ Model or test data not available\")\n",
    "    forecast_results = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f58a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate forecasts for specific test cases for visualization\n",
    "if model is not None and len(test_cases) > 0:\n",
    "    print(\"ðŸ“ˆ Preparing forecasts for visualization...\")\n",
    "    \n",
    "    # Select a few test cases for detailed visualization\n",
    "    viz_cases = test_cases[:5] if len(test_cases) >= 5 else test_cases\n",
    "    \n",
    "    case_forecasts = {}\n",
    "    \n",
    "    for caseid in viz_cases:\n",
    "        try:\n",
    "            # Get case data\n",
    "            case_data = normalized_data[normalized_data['caseid'] == caseid].sort_values('timestamp').reset_index(drop=True)\n",
    "            \n",
    "            if len(case_data) < SEQ_LENGTH + FORECAST_HORIZON:\n",
    "                continue\n",
    "            \n",
    "            # Create sequences for this case\n",
    "            case_sequences = []\n",
    "            case_actuals = []\n",
    "            case_timestamps = []\n",
    "            \n",
    "            # Generate multiple forecasts along the case timeline\n",
    "            step_size = FORECAST_HORIZON  # Non-overlapping forecasts\n",
    "            for i in range(0, len(case_data) - SEQ_LENGTH - FORECAST_HORIZON + 1, step_size):\n",
    "                seq = case_data.iloc[i:i+SEQ_LENGTH][available_features].values\n",
    "                target_idx = i + SEQ_LENGTH + FORECAST_HORIZON - 1\n",
    "                \n",
    "                if target_idx < len(case_data):\n",
    "                    case_sequences.append(seq)\n",
    "                    case_actuals.append(case_data.iloc[target_idx]['mbp'])\n",
    "                    case_timestamps.append(case_data.iloc[target_idx]['timestamp'])\n",
    "            \n",
    "            if len(case_sequences) > 0:\n",
    "                # Predict\n",
    "                case_X = np.array(case_sequences)\n",
    "                case_pred = model.predict(case_X, verbose=0).flatten()\n",
    "                \n",
    "                # Get original MBP values for denormalization\n",
    "                case_original = data[data['caseid'] == caseid].sort_values('timestamp').reset_index(drop=True)\n",
    "                case_mbp_mean = case_original['mbp'].mean()\n",
    "                case_mbp_std = case_original['mbp'].std()\n",
    "                \n",
    "                # Denormalize\n",
    "                denorm_actual = np.array(case_actuals) * case_mbp_std + case_mbp_mean\n",
    "                denorm_pred = case_pred * case_mbp_std + case_mbp_mean\n",
    "                \n",
    "                # Get full timeline\n",
    "                full_timestamps = case_original['timestamp'].values\n",
    "                full_actual_mbp = case_original['mbp'].values\n",
    "                \n",
    "                case_forecasts[caseid] = {\n",
    "                    'timestamps': full_timestamps,\n",
    "                    'actual_mbp': full_actual_mbp,\n",
    "                    'forecast_timestamps': [case_original.iloc[int(ts)]['timestamp'] if int(ts) < len(case_original) else None \n",
    "                                          for ts in case_timestamps],\n",
    "                    'forecast_actual': denorm_actual,\n",
    "                    'forecast_predicted': denorm_pred\n",
    "                }\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  âš ï¸ Error processing case {caseid}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"âœ… Prepared forecasts for {len(case_forecasts)} cases\")\n",
    "    print(f\"  - Cases: {list(case_forecasts.keys())}\")\n",
    "else:\n",
    "    case_forecasts = {}\n",
    "    print(\"âŒ Could not prepare case forecasts\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306b82f9",
   "metadata": {},
   "source": [
    "## Visualize Forecasts\n",
    "\n",
    "Create visualizations showing actual vs forecasted MBP for multiple case IDs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895a575d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization plots\n",
    "if len(case_forecasts) > 0:\n",
    "    print(\"ðŸ“Š Creating visualization plots...\")\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.dates as mdates\n",
    "    from datetime import datetime, timedelta\n",
    "    from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "    \n",
    "    # Create subplots\n",
    "    n_cases = len(case_forecasts)\n",
    "    fig, axes = plt.subplots(n_cases, 1, figsize=(14, 4 * n_cases))\n",
    "    \n",
    "    if n_cases == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for idx, (caseid, forecast_data) in enumerate(case_forecasts.items()):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # Plot actual MBP over time\n",
    "        timestamps = forecast_data['timestamps']\n",
    "        actual_mbp = forecast_data['actual_mbp']\n",
    "        \n",
    "        # Convert timestamps to minutes for readability\n",
    "        time_minutes = timestamps / 60\n",
    "        \n",
    "        ax.plot(time_minutes, actual_mbp, 'b-', alpha=0.6, label='Actual MBP', linewidth=1.5)\n",
    "        \n",
    "        # Plot forecast points\n",
    "        if len(forecast_data['forecast_timestamps']) > 0:\n",
    "            forecast_ts = [t/60 if t is not None else None for t in forecast_data['forecast_timestamps']]\n",
    "            forecast_ts = [t for t in forecast_ts if t is not None]\n",
    "            \n",
    "            if len(forecast_ts) == len(forecast_data['forecast_predicted']):\n",
    "                ax.scatter(forecast_ts, forecast_data['forecast_actual'], \n",
    "                          color='green', marker='o', s=50, label='Actual (forecast points)', zorder=5)\n",
    "                ax.scatter(forecast_ts, forecast_data['forecast_predicted'], \n",
    "                          color='red', marker='x', s=100, linewidths=2, label='Forecasted MBP', zorder=5)\n",
    "        \n",
    "        # Add forecast horizon indicator\n",
    "        if len(forecast_ts) > 0:\n",
    "            # Show forecast horizon on first forecast point\n",
    "            first_forecast_time = forecast_ts[0]\n",
    "            ax.axvspan(first_forecast_time, first_forecast_time + FORECAST_HORIZON/60, \n",
    "                      alpha=0.2, color='yellow', label=f'{FORECAST_HORIZON}-sec forecast horizon')\n",
    "        \n",
    "        ax.set_xlabel('Time (minutes)', fontsize=11)\n",
    "        ax.set_ylabel('Mean Blood Pressure (mmHg)', fontsize=11)\n",
    "        ax.set_title(f'Case ID {caseid}: Actual vs Forecasted MBP', fontsize=12, fontweight='bold')\n",
    "        ax.legend(loc='best', fontsize=9)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Calculate and display metrics for this case using numba-optimized functions\n",
    "        if len(forecast_data['forecast_predicted']) > 0:\n",
    "            case_actual_array = np.array(forecast_data['forecast_actual'], dtype=np.float64)\n",
    "            case_pred_array = np.array(forecast_data['forecast_predicted'], dtype=np.float64)\n",
    "            case_mae = calculate_mae_numba(case_actual_array, case_pred_array)\n",
    "            case_rmse = calculate_rmse_numba(case_actual_array, case_pred_array)\n",
    "            \n",
    "            ax.text(0.02, 0.98, f'MAE: {case_mae:.2f} mmHg | RMSE: {case_rmse:.2f} mmHg',\n",
    "                   transform=ax.transAxes, fontsize=9, verticalalignment='top',\n",
    "                   bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('transplantation_bp_forecasts.png', dpi=150, bbox_inches='tight')\n",
    "    print(f\"âœ… Visualization saved to transplantation_bp_forecasts.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Create a summary comparison plot\n",
    "    if len(case_forecasts) > 1:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "        \n",
    "        all_actual = []\n",
    "        all_predicted = []\n",
    "        \n",
    "        for caseid, forecast_data in case_forecasts.items():\n",
    "            all_actual.extend(forecast_data['forecast_actual'])\n",
    "            all_predicted.extend(forecast_data['forecast_predicted'])\n",
    "        \n",
    "        all_actual = np.array(all_actual)\n",
    "        all_predicted = np.array(all_predicted)\n",
    "        \n",
    "        # Scatter plot\n",
    "        ax.scatter(all_actual, all_predicted, alpha=0.6, s=50)\n",
    "        \n",
    "        # Perfect prediction line\n",
    "        min_val = min(min(all_actual), min(all_predicted))\n",
    "        max_val = max(max(all_actual), max(all_predicted))\n",
    "        ax.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Perfect Prediction')\n",
    "        \n",
    "        ax.set_xlabel('Actual MBP (mmHg)', fontsize=12)\n",
    "        ax.set_ylabel('Forecasted MBP (mmHg)', fontsize=12)\n",
    "        ax.set_title('Actual vs Forecasted MBP - All Test Cases', fontsize=13, fontweight='bold')\n",
    "        ax.legend(fontsize=10)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add metrics text using numba-optimized functions\n",
    "        overall_actual_array = all_actual.astype(np.float64)\n",
    "        overall_pred_array = all_predicted.astype(np.float64)\n",
    "        overall_mae = calculate_mae_numba(overall_actual_array, overall_pred_array)\n",
    "        overall_rmse = calculate_rmse_numba(overall_actual_array, overall_pred_array)\n",
    "        overall_mape = calculate_mape_numba(overall_actual_array, overall_pred_array)\n",
    "        \n",
    "        textstr = f'MAE: {overall_mae:.2f} mmHg\\nRMSE: {overall_rmse:.2f} mmHg\\nMAPE: {overall_mape:.2f}%'\n",
    "        ax.text(0.05, 0.95, textstr, transform=ax.transAxes, fontsize=11,\n",
    "               verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('transplantation_bp_scatter.png', dpi=150, bbox_inches='tight')\n",
    "        print(f\"âœ… Scatter plot saved to transplantation_bp_scatter.png\")\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"âŒ No forecast data available for visualization\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a037cb8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
